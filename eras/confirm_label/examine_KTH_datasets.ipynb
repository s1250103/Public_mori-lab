{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "examine_KTH_datasets.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKkXYgIPNdsOhgNQsGrBaw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1250103/Public_mori-lab/blob/confirm_label_noize_for_cm_data/eras/confirm_label/examine_KTH_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn8mY7TNKCVG"
      },
      "source": [
        "#環境設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jJi-oO2J_on"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "## import\n",
        "# file dealing\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "# data dealing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "# process deasing\n",
        "import gc\n",
        "from time import sleep\n",
        "\n",
        "# machine learning (back)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import layers, models, initializers, callbacks\n",
        "\n",
        "# machine learning\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import pprint\n",
        "import re\n",
        "import requests"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CemsuBxCnpSD"
      },
      "source": [
        "# 実験条件（外乱）を定める"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXCV5Urc5PUH"
      },
      "source": [
        "LABEL_NOISE_RATE = 0\n",
        "TEST_DATA_RATE = 0.25"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FH7fepQ6Fo1"
      },
      "source": [
        "#学習条件を定める"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UScShR1lmM_U"
      },
      "source": [
        "##学習手法の仕様"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUl9mQXfk7eS"
      },
      "source": [
        "seed = 20201218\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "learningDict = {\n",
        "    \"optimizer\" : {\n",
        "        \"this.optimizer\" : \"sgd\",\n",
        "        \"learning_rate\" : 1e-5,\n",
        "        \"momentum\" : 0,\n",
        "        \"decay\" : 0.1,\n",
        "        \"nesterov\" : False\n",
        "    },\n",
        "    \"theWay\" : {\n",
        "        \"batch_size\" : 4,\n",
        "        \"epochs\" : 1024,\n",
        "    },\n",
        "    \"compared_losses\" : [\n",
        "                        #  tf.keras.losses.CategoricalCrossentropy(),\n",
        "                        #  tf.keras.losses.MeanSquaredError(), \n",
        "                         tf.keras.losses.MeanAbsoluteError(),\n",
        "                        #  tf.keras.losses.SquaredHinge()               \n",
        "    ]\n",
        "}\n",
        "\n",
        "def compile_optimizer():\n",
        "  # 最適化処理 (adamのみ対応)\n",
        "  if learningDict[\"optimizer\"][\"this.optimizer\"] == \"adam\":\n",
        "    optimizer = keras.optimizers.Adam(\n",
        "        lr=learningDict[\"optimizer\"][\"learning_rate\"],\n",
        "        beta_1=learningDict[\"optimizer\"][\"beta_1\"],\n",
        "        beta_2=learningDict[\"optimizer\"][\"beta_2\"])\n",
        "    print(\"adam is used as a optimizer\")\n",
        "\n",
        "  elif learningDict[\"optimizer\"][\"this.optimizer\"] == \"Nadam\":\n",
        "    optimizer = keras.optimizers.Nadam(\n",
        "        lr=learningDict[\"optimizer\"][\"learning_rate\"],\n",
        "        beta_1=learningDict[\"optimizer\"][\"beta_1\"],\n",
        "        beta_2=learningDict[\"optimizer\"][\"beta_2\"],\n",
        "        epsilon=None, \n",
        "        schedule_decay=0.4)\n",
        "    print(\"Nadam is used as a optimizer\")\n",
        "\n",
        "  elif learningDict[\"optimizer\"][\"this.optimizer\"] == \"sgd\":\n",
        "    optimizer = keras.optimizers.SGD(\n",
        "        lr=learningDict[\"optimizer\"][\"learning_rate\"],\n",
        "        momentum=learningDict[\"optimizer\"][\"momentum\"],\n",
        "        decay=learningDict[\"optimizer\"][\"decay\"],\n",
        "        nesterov=learningDict[\"optimizer\"][\"nesterov\"]) \n",
        "    print(\"sgd is used as a optimizer\")\n",
        "  else:\n",
        "    print(\"error\")\n",
        "  \n",
        "  return optimizer"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXCt9_EOhkSt"
      },
      "source": [
        "## モデルの仕様（ニューラルネットワーク）\n",
        "<ul>\n",
        "  <li>入力層(フレームサイズ, フレームの高さ, フレームの横幅, RGB情報) </li>\n",
        "  <li>出力層(予測値) </li>\n",
        "  <li> 中間層 \n",
        "    <ol>\n",
        "      <li>conv0</li>\n",
        "      <li>pool0</li>\n",
        "      <li>conv1</li>\n",
        "      <li>pool1</li>\n",
        "      <li>dence0</li>\n",
        "  </li>\n",
        "</ui>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeda9UgKf23z"
      },
      "source": [
        "def make_model(video_format):\n",
        "  # モデル作成\n",
        "  model = models.Sequential()\n",
        "  # 入力層\n",
        "  model.add(\n",
        "      layers.Reshape(\n",
        "          (video_format.FRAME_SIZE,\n",
        "          video_format.HEIGHT,\n",
        "          video_format.WIDTH,\n",
        "          video_format.COLORinfo),\n",
        "          input_shape=(video_format.FRAME_SIZE * video_format.HEIGHT * video_format.WIDTH * video_format.COLORinfo,),\n",
        "          name='Input_Layer' )\n",
        "  )\n",
        "  # 畳み込み0\n",
        "  model.add(\n",
        "      layers.Conv3D(\n",
        "          filters=32,\n",
        "          kernel_size=(3, 3, 3),\n",
        "          strides=(1, 1, 1),\n",
        "          padding='same',\n",
        "          activation='relu',\n",
        "          name='conv0'))\n",
        "  # pool0\n",
        "  model.add(\n",
        "      layers.MaxPooling3D(pool_size=(2, 2, 2), name='pool0'))\n",
        "\n",
        "  # 畳み込み1\n",
        "  model.add(\n",
        "      layers.Conv3D(\n",
        "          filters=32,\n",
        "          kernel_size=(3, 3, 3),\n",
        "          strides=(1, 1, 1),\n",
        "          padding='same',\n",
        "          activation='relu',\n",
        "          name='conv1'))\n",
        "  # pool1\n",
        "  model.add(\n",
        "      layers.MaxPooling3D(pool_size=(2, 2, 2), name='pool1'))\n",
        "\n",
        "  # dence\n",
        "  model.add(\n",
        "      layers.Dense(1024,\n",
        "        activation='relu',\n",
        "        name='dence0' ),\n",
        "  )\n",
        "  # 出力層\n",
        "  model.add(\n",
        "      layers.Dense(4, activation='softmax', name='WATERSUPPLY')\n",
        "  )\n",
        "  return model\n"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEbRDHGlku0r"
      },
      "source": [
        "##データの仕様"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-SMSh_TkVjG"
      },
      "source": [
        "## フォーマットの設定\n",
        "class video_format:\n",
        "  # 想定された入力CMデータの仕様\n",
        "  playtime = \"15秒\"\n",
        "  displaysize = \"(any, any, RGB)\"\n",
        "  videoformat = \"any\"\n",
        "  # モデルが扱うCMデータ(上のようなデータは、下のように変換される)\n",
        "  HEIGHT = 45\n",
        "  WIDTH = 80\n",
        "  FRAME_SIZE = 30\n",
        "  COLORinfo = 3 # \"RGB\"\n",
        "  FPS = \"2 (FRAME_SIZE / playtime)\" # 定義ではなく上から計算される値"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnSHYRFpKdfa"
      },
      "source": [
        "# 学習データの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00VyH9N3Kl8h",
        "outputId": "8cd5eef2-4139-482d-f8d9-9834ad25dad5"
      },
      "source": [
        "## gdrive 接続\n",
        "if not path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print(\"Already confirm\")\n",
        "\n",
        "## colab テンポラリディレクトリの作成\n",
        "desk = '/content/desk'\n",
        "if not os.path.exists(desk):\n",
        "  os.mkdir(desk)\n",
        "os.chdir(desk)\n",
        "print(\"Created at /content/desk\")"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already confirm\n",
            "Created at /content/desk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjO2EXNfnW1i"
      },
      "source": [
        "learning_data_path = \"/content/drive/MyDrive/colab/cleaned_detasets/KTH\""
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNUgCm4Ina0K",
        "outputId": "aa7c49d4-85f3-4ea4-ae79-b0b746adb791"
      },
      "source": [
        "if path.isdir(learning_data_path):\n",
        "  print(\"actually exist the\", learning_data_path)\n",
        "  for each_data in os.listdir(learning_data_path):\n",
        "    if re.match(r\"Data.*\\.npz\", each_data):\n",
        "      print(\"________|------------ reading [\", each_data, \"] as learning data.\")\n",
        "      learning_data_np = np.load(path.join(learning_data_path, each_data))\n",
        "    elif re.match(r\"Label.*\\.npz\", each_data):\n",
        "      print(\"________|------------ reading [\", each_data, \"] as label data.\")\n",
        "      label_data_np = np.load(path.join(learning_data_path, each_data))\n",
        "    else:\n",
        "      print(\"no such path\")\n",
        "else:\n",
        "  print(\"no such path\")\n"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actually exist the /content/drive/MyDrive/colab/cleaned_detasets/KTH\n",
            "________|------------ reading [ Data_of_KTH.npz ] as learning data.\n",
            "________|------------ reading [ Label_of_KTH.npz ] as label data.\n",
            "no such path\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HzCVZtzp4d1"
      },
      "source": [
        "## 訓練データとテストデータとで分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBPqzDUMqokn"
      },
      "source": [
        "learning_data = []\n",
        "label_data = []\n",
        "for i in learning_data_np.files:\n",
        "  learning_data.append(learning_data_np[i])\n",
        "for i in label_data_np.files:\n",
        "  label_data.append(label_data_np[i])\n",
        "\n",
        "# learning_data = np.array(learning_data, dtype=object)\n",
        "# label_data = np.array(label_data)"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvMlS5Ub-RJN",
        "outputId": "145dd152-f5f7-47cb-8a5a-1ac15edac2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "learning_data[0]"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5529412 , 0.5529412 , 0.5529412 , ..., 0.47843137, 0.47843137,\n",
              "       0.47843137], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLs_Ii0g-n6-",
        "outputId": "9f37d43b-e58c-4779-b35a-8ce736525602",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = np.array(learning_data)\n",
        "a.shape"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHeiuRSl2ATW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(learning_data, label_data, random_state=20200120, train_size=(1-TEST_DATA_RATE))"
      ],
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGBqKQYE8ajq",
        "outputId": "38917072-c2d8-4666-f1e7-5d37bf7b6482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DoTGxOV5Ach"
      },
      "source": [
        "## テストデータに意図的なノイズを加える(実験のために)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXMxF1H-645e"
      },
      "source": [
        "import random\n",
        "def rand_ints_nodup(a, b, k):\n",
        "  ns = []\n",
        "  while len(ns) < k:\n",
        "    n = random.randint(a, b)\n",
        "    if not n in ns:\n",
        "      ns.append(n)\n",
        "  return ns\n",
        "def changed_number(original_num, set_min, set_max):\n",
        "  while True:\n",
        "    tmpRndVal = random.randint(set_min, set_max)\n",
        "    if original_num != tmpRndVal:\n",
        "      return tmpRndVal"
      ],
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6rf5RcI7AzI",
        "outputId": "18b45673-aad0-4441-a522-1b32b3400ac6"
      },
      "source": [
        "changed_label_number_for_experiment = int(len(Y_test) * LABEL_NOISE_RATE)\n",
        "change_points = rand_ints_nodup(0, len(Y_test)-1, changed_label_number_for_experiment )\n",
        "print(\"change map:\", sorted(change_points))\n",
        "print(\"the size:\", len(change_points))\n",
        "\n",
        "set_min = np.min(Y_test)\n",
        "set_max = np.max(Y_test)\n",
        "for i in range(len(Y_test)):\n",
        "  if i in change_points:\n",
        "    print(\"No.\", i, \", original number is\", Y_test[i], end=\" -> \")\n",
        "    Y_test[i] = changed_number(Y_test[i], set_min, set_max)\n",
        "    print(\"changed number is\", Y_test[i])\n",
        "  else:\n",
        "    print(\"error\")\n",
        "    break\n",
        "  "
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "change map: []\n",
            "the size: 0\n",
            "error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiRg42hvLcYE"
      },
      "source": [
        "## 適切な形に処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAjtSgxaGvBz"
      },
      "source": [
        "# 学習開始"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo8L79Rx9FTE",
        "outputId": "714d2d04-6181-46ca-8846-433c33909700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2pRCWcp86oD",
        "outputId": "544f2bda-6a21-4de3-873a-63dc9c7faa03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "X_train = np.asarray(X_train).astype(np.float32)"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-317-8616a0a51ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "LXCHuDWpGxz-",
        "outputId": "73eece21-6129-42cf-f25c-193715b75e7f"
      },
      "source": [
        "obj_video_format = video_format()\n",
        "\n",
        "histories = []\n",
        "for i, each_loss in enumerate(learningDict[\"compared_losses\"]):\n",
        "  print(each_loss)\n",
        "  # print(re.search(r))\n",
        "\n",
        "  # モデル構築\n",
        "  model = make_model(obj_video_format)\n",
        "  model.compile(\n",
        "        optimizer=compile_optimizer(),\n",
        "        loss=each_loss,\n",
        "        metrics=['acc'])\n",
        "  # 実行\n",
        "\n",
        "  history = model.fit(\n",
        "        X_train, Y_train,\n",
        "        # a, b,\n",
        "        # validation_data=(X_test, Y_test),\n",
        "        batch_size=learningDict[\"theWay\"][\"batch_size\"],\n",
        "        epochs=10\n",
        "        # verbose=0\n",
        "        )\n",
        "  histories.append(history)\n",
        "  print(\"Complete.\")"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.losses.MeanAbsoluteError object at 0x7f8663fd7b38>\n",
            "sgd is used as a optimizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-316-45b10292adc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# validation_data=(X_test, Y_test),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"theWay\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# verbose=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                **kwargs):\n\u001b[1;32m    262\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    265\u001b[0m         sample_weights, sample_weight_modes)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1403\u001b[0m   \"\"\"\n\u001b[1;32m   1404\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1405\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9laVNUpmLNey",
        "outputId": "c37fe038-48f6-4fa6-b676-a9ca369e1d41"
      },
      "source": [
        "  sleep(10)\n",
        "  del model\n",
        "  keras.backend.clear_session()\n",
        "  gc.collect()"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kLrBLvsLB19",
        "outputId": "c24eacfa-f4d9-445c-889f-b286015cd22d"
      },
      "source": [
        "learningDict[\"theWay\"][\"epochs\"]"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s08KXCe9HsfF",
        "outputId": "d83c4420-8730-43ca-a707-9a65aa5755a1"
      },
      "source": [
        "m = re.search(r'\\d+', s)\n",
        "\n",
        "print(m.group())"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.losses.MeanAbsoluteError at 0x7f8668403358>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    }
  ]
}