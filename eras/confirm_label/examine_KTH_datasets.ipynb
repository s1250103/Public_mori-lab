{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "examine_KTH_datasets.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1250103/Public_mori-lab/blob/confirm_label_noize_for_cm_data/eras/confirm_label/examine_KTH_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn8mY7TNKCVG"
      },
      "source": [
        "#環境設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jJi-oO2J_on"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "## import\n",
        "# file dealing\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "# data dealing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "# process deasing\n",
        "import gc\n",
        "from time import sleep\n",
        "\n",
        "# machine learning (back)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import layers, models, initializers, callbacks\n",
        "\n",
        "# machine learning\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import pprint\n",
        "import re\n",
        "import requests\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxGMERAvX3P8"
      },
      "source": [
        "def send_line_notify(notification_message):\n",
        "    \"\"\"\n",
        "    LINEに通知する\n",
        "    \"\"\"\n",
        "    line_notify_token = 'cHdELzsau6ve8hNVL3FxPz65Jdyquzuj2kd021u8q1L'\n",
        "    line_notify_api = 'https://notify-api.line.me/api/notify'\n",
        "    headers = {'Authorization': f'Bearer {line_notify_token}'}\n",
        "    data = {'message': notification_message}\n",
        "    requests.post(line_notify_api, headers = headers, data = data)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CemsuBxCnpSD"
      },
      "source": [
        "# 実験条件（外乱）を定める"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXCV5Urc5PUH"
      },
      "source": [
        "LABEL_NOISE_RATE = 0.4\n",
        "TEST_DATA_RATE = 0.25\n",
        "EXPERIMENTS_NUMBER = 6"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FH7fepQ6Fo1"
      },
      "source": [
        "#学習条件を定める"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UScShR1lmM_U"
      },
      "source": [
        "##学習手法の仕様"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUl9mQXfk7eS"
      },
      "source": [
        "seed = 20201218\n",
        "\n",
        "learningDict = {\n",
        "    \"optimizer\" : {\n",
        "        \"this.optimizer\" : \"sgd\",\n",
        "        \"learning_rate\" : 0.01,\n",
        "        \"momentum\" : 0.9,\n",
        "        \"decay\" : 1e-4,\n",
        "        \"nesterov\" : True\n",
        "    },\n",
        "    \"theWay\" : {\n",
        "        \"batch_size\" : 32,\n",
        "        \"epochs\" : 128,\n",
        "    },\n",
        "    \"compared_losses\" : [\n",
        "                         tf.keras.losses.CategoricalCrossentropy(),\n",
        "                         tf.keras.losses.MeanSquaredError(), \n",
        "                         tf.keras.losses.MeanAbsoluteError(),\n",
        "                        #  tf.keras.losses.SquaredHinge()               \n",
        "    ]\n",
        "}\n",
        "\n",
        "# learningDict = {\n",
        "#     \"optimizer\" : {\n",
        "#         \"this.optimizer\" : \"adam\",\n",
        "#         \"learning_rate\" : 0.001,\n",
        "#         \"epsilon\" : 1e-8,\n",
        "#         \"beta_1\" : 0.9,\n",
        "#         \"beta_2\" : 0.999\n",
        "#     },\n",
        "#     \"theWay\" : {\n",
        "#         \"batch_size\" : 32,\n",
        "#         \"epochs\" : 128,\n",
        "#     },\n",
        "#     \"compared_losses\" : [\n",
        "#                         tf.keras.losses.MeanAbsoluteError(),\n",
        "#     ]\n",
        "# }\n",
        "\n",
        "def compile_optimizer():\n",
        "  # 最適化処理 (adamのみ対応)\n",
        "  if learningDict[\"optimizer\"][\"this.optimizer\"] == \"adam\":\n",
        "    optimizer = keras.optimizers.Adam(\n",
        "        lr=learningDict[\"optimizer\"][\"learning_rate\"],\n",
        "        epsilon=learningDict[\"optimizer\"][\"epsilon\"],\n",
        "        beta_1=learningDict[\"optimizer\"][\"beta_1\"],\n",
        "        beta_2=learningDict[\"optimizer\"][\"beta_2\"])\n",
        "    print(\"adam is used as a optimizer\")\n",
        "\n",
        "  elif learningDict[\"optimizer\"][\"this.optimizer\"] == \"Nadam\":\n",
        "    optimizer = keras.optimizers.Nadam(\n",
        "        lr=learningDict[\"optimizer\"][\"learning_rate\"],\n",
        "        beta_1=learningDict[\"optimizer\"][\"beta_1\"],\n",
        "        beta_2=learningDict[\"optimizer\"][\"beta_2\"],\n",
        "        epsilon=None, \n",
        "        schedule_decay=0.4)\n",
        "    print(\"Nadam is used as a optimizer\")\n",
        "\n",
        "  elif learningDict[\"optimizer\"][\"this.optimizer\"] == \"sgd\":\n",
        "    optimizer = keras.optimizers.SGD(\n",
        "        lr=learningDict[\"optimizer\"][\"learning_rate\"],\n",
        "        momentum=learningDict[\"optimizer\"][\"momentum\"],\n",
        "        decay=learningDict[\"optimizer\"][\"decay\"],\n",
        "        nesterov=learningDict[\"optimizer\"][\"nesterov\"]) \n",
        "    print(\"sgd is used as a optimizer\")\n",
        "  else:\n",
        "    print(\"error\")\n",
        "  \n",
        "  return optimizer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXCt9_EOhkSt"
      },
      "source": [
        "## モデルの仕様（ニューラルネットワーク）\n",
        "<ul>\n",
        "  <li>入力層(フレームサイズ, フレームの高さ, フレームの横幅, RGB情報) </li>\n",
        "  <li>出力層(予測値) </li>\n",
        "  <li> 中間層 \n",
        "    <ol>\n",
        "      <li>conv0</li>\n",
        "      <li>pool0</li>\n",
        "      <li>conv1</li>\n",
        "      <li>pool1</li>\n",
        "      <li>dence0</li>\n",
        "  </li>\n",
        "</ui>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeda9UgKf23z"
      },
      "source": [
        "def make_model(video_format):\n",
        "  # モデル作成\n",
        "  model = models.Sequential()\n",
        "  # 入力層\n",
        "  model.add(\n",
        "      layers.Reshape(\n",
        "          (video_format.FRAME_SIZE,\n",
        "          video_format.HEIGHT,\n",
        "          video_format.WIDTH,\n",
        "          video_format.COLORinfo),\n",
        "          input_shape=(video_format.FRAME_SIZE * video_format.HEIGHT * video_format.WIDTH * video_format.COLORinfo,),\n",
        "          name='Input_Layer' )\n",
        "  )\n",
        "  # 畳み込み0\n",
        "  model.add(\n",
        "      layers.Conv3D(\n",
        "          filters=32,\n",
        "          kernel_size=(3, 3, 3),\n",
        "          strides=(1, 1, 1),\n",
        "          padding='same',\n",
        "          activation='relu',\n",
        "          name='conv0'))\n",
        "  # pool0\n",
        "  model.add(\n",
        "      layers.MaxPooling3D(pool_size=(2, 2, 2), name='pool0'))\n",
        "\n",
        "  # 畳み込み1\n",
        "  model.add(\n",
        "      layers.Conv3D(\n",
        "          filters=32,\n",
        "          kernel_size=(3, 3, 3),\n",
        "          strides=(1, 1, 1),\n",
        "          padding='same',\n",
        "          activation='relu',\n",
        "          name='conv1'))\n",
        "  # pool1\n",
        "  model.add(\n",
        "      layers.MaxPooling3D(pool_size=(2, 2, 2), name='pool1'))\n",
        "\n",
        "  ## 全結合0\n",
        "  model.add(\n",
        "      layers.Flatten(name='pipe'),\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(1024,\n",
        "        activation='relu',\n",
        "        name='dence0' ),\n",
        "  )\n",
        "  # 出力層\n",
        "  model.add(\n",
        "      layers.Dense(4, activation='softmax', name='WATERSUPPLY')\n",
        "  )\n",
        "  return model\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEbRDHGlku0r"
      },
      "source": [
        "##データの仕様"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-SMSh_TkVjG"
      },
      "source": [
        "## フォーマットの設定\n",
        "class video_format:\n",
        "  # 想定された入力CMデータの仕様\n",
        "  playtime = \"15秒\"\n",
        "  displaysize = \"(any, any, RGB)\"\n",
        "  videoformat = \"any\"\n",
        "  # モデルが扱うCMデータ(上のようなデータは、下のように変換される)\n",
        "  HEIGHT = 45\n",
        "  WIDTH = 80\n",
        "  FRAME_SIZE = 30\n",
        "  COLORinfo = 3 # \"RGB\"\n",
        "  FPS = \"2 (FRAME_SIZE / playtime)\" # 定義ではなく上から計算される値"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnSHYRFpKdfa"
      },
      "source": [
        "# 学習データの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00VyH9N3Kl8h",
        "outputId": "09103f30-1a7a-4f22-e756-58425b7e547a"
      },
      "source": [
        "## gdrive 接続\n",
        "if not path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print(\"Already confirm\")\n",
        "\n",
        "## colab テンポラリディレクトリの作成\n",
        "desk = '/content/desk'\n",
        "if not os.path.exists(desk):\n",
        "  os.mkdir(desk)\n",
        "os.chdir(desk)\n",
        "print(\"Created at /content/desk\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Created at /content/desk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjO2EXNfnW1i"
      },
      "source": [
        "learning_data_path = \"/content/drive/MyDrive/colab/cleaned_detasets/KTH\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNUgCm4Ina0K",
        "outputId": "96a0b2af-6bcd-42e4-8760-ba7655dc31ae"
      },
      "source": [
        "if path.isdir(learning_data_path):\n",
        "  print(\"actually exist the\", learning_data_path)\n",
        "  for each_data in os.listdir(learning_data_path):\n",
        "    if re.match(r\"Data.*\\.npz\", each_data):\n",
        "      print(\"________|------------ reading [\", each_data, \"] as learning data.\")\n",
        "      learning_data_np = np.load(path.join(learning_data_path, each_data))\n",
        "    elif re.match(r\"Label.*\\.npz\", each_data):\n",
        "      print(\"________|------------ reading [\", each_data, \"] as label data.\")\n",
        "      label_data_np = np.load(path.join(learning_data_path, each_data))\n",
        "    else:\n",
        "      print(\"Not reading such data\", each_data)\n",
        "else:\n",
        "  print(\"no such path\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actually exist the /content/drive/MyDrive/colab/cleaned_detasets/KTH\n",
            "Not reading such data .ipynb_checkpoints\n",
            "________|------------ reading [ Data_of_KTH.npz ] as learning data.\n",
            "________|------------ reading [ Label_of_KTH.npz ] as label data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBPqzDUMqokn"
      },
      "source": [
        "learning_data = []\n",
        "label_data = []\n",
        "for i in learning_data_np.files:\n",
        "  learning_data.append(learning_data_np[i])\n",
        "for i in label_data_np.files:\n",
        "  label_data.append(label_data_np[i])\n",
        "\n",
        "learning_data = np.array(learning_data)\n",
        "label_data = np.array(label_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HzCVZtzp4d1"
      },
      "source": [
        "## 訓練データとテストデータとで分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHeiuRSl2ATW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(learning_data, label_data, random_state=20200120, train_size=(1-TEST_DATA_RATE))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DoTGxOV5Ach"
      },
      "source": [
        "## テストデータの教師ラベルに意図的なノイズを加える(実験のために)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXMxF1H-645e"
      },
      "source": [
        "import random\n",
        "def rand_ints_nodup(a, b, k):\n",
        "  ns = []\n",
        "  while len(ns) < k:\n",
        "    n = random.randint(a, b)\n",
        "    if not n in ns:\n",
        "      ns.append(n)\n",
        "  return ns\n",
        "def changed_number(original_num, set_min, set_max):\n",
        "  while True:\n",
        "    tmpRndVal = random.randint(set_min, set_max)\n",
        "    if original_num != tmpRndVal:\n",
        "      return tmpRndVal"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6rf5RcI7AzI",
        "outputId": "1cb160f1-211d-46e2-ed51-464cf356daa2"
      },
      "source": [
        "changed_label_number_for_experiment = int(len(Y_test) * LABEL_NOISE_RATE)\n",
        "change_points = rand_ints_nodup(0, len(Y_test)-1, changed_label_number_for_experiment )\n",
        "print(\"change map:\", sorted(change_points))\n",
        "print(\"the size:\", len(change_points))\n",
        "\n",
        "set_min = np.min(Y_test)\n",
        "set_max = np.max(Y_test)\n",
        "sum = 0\n",
        "if LABEL_NOISE_RATE != 0:\n",
        "  for i in range(len(Y_test)):\n",
        "    if i in change_points:\n",
        "      print(\"No.\", i, \", original number is\", Y_test[i], end=\" -> \")\n",
        "      Y_test[i] = changed_number(Y_test[i], set_min, set_max)\n",
        "      print(\"changed number is\", Y_test[i])\n",
        "      sum += 1\n",
        "    else:\n",
        "      pass\n",
        "else:\n",
        "  print(\"No label noizes\")\n",
        "  \n",
        "if sum == len(change_points):\n",
        "  print(\"changed correctlly.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "change map: [4, 6, 11, 14, 15, 16, 18, 22, 29, 30, 35, 37, 41, 44, 47, 48, 49, 50, 51, 54, 59, 60, 61, 62, 63, 66, 70, 71, 72, 78, 83, 85, 86, 90, 91, 92, 93, 94, 97, 98]\n",
            "the size: 40\n",
            "No. 4 , original number is 2 -> changed number is 1\n",
            "No. 6 , original number is 2 -> changed number is 1\n",
            "No. 11 , original number is 0 -> changed number is 2\n",
            "No. 14 , original number is 0 -> changed number is 1\n",
            "No. 15 , original number is 0 -> changed number is 1\n",
            "No. 16 , original number is 0 -> changed number is 2\n",
            "No. 18 , original number is 1 -> changed number is 0\n",
            "No. 22 , original number is 1 -> changed number is 2\n",
            "No. 29 , original number is 0 -> changed number is 2\n",
            "No. 30 , original number is 3 -> changed number is 2\n",
            "No. 35 , original number is 1 -> changed number is 3\n",
            "No. 37 , original number is 2 -> changed number is 3\n",
            "No. 41 , original number is 2 -> changed number is 1\n",
            "No. 44 , original number is 2 -> changed number is 0\n",
            "No. 47 , original number is 0 -> changed number is 1\n",
            "No. 48 , original number is 2 -> changed number is 1\n",
            "No. 49 , original number is 3 -> changed number is 2\n",
            "No. 50 , original number is 1 -> changed number is 3\n",
            "No. 51 , original number is 3 -> changed number is 0\n",
            "No. 54 , original number is 3 -> changed number is 1\n",
            "No. 59 , original number is 1 -> changed number is 3\n",
            "No. 60 , original number is 3 -> changed number is 1\n",
            "No. 61 , original number is 3 -> changed number is 0\n",
            "No. 62 , original number is 1 -> changed number is 3\n",
            "No. 63 , original number is 2 -> changed number is 3\n",
            "No. 66 , original number is 3 -> changed number is 2\n",
            "No. 70 , original number is 1 -> changed number is 3\n",
            "No. 71 , original number is 3 -> changed number is 0\n",
            "No. 72 , original number is 0 -> changed number is 2\n",
            "No. 78 , original number is 0 -> changed number is 2\n",
            "No. 83 , original number is 1 -> changed number is 0\n",
            "No. 85 , original number is 0 -> changed number is 2\n",
            "No. 86 , original number is 1 -> changed number is 2\n",
            "No. 90 , original number is 3 -> changed number is 2\n",
            "No. 91 , original number is 1 -> changed number is 3\n",
            "No. 92 , original number is 3 -> changed number is 2\n",
            "No. 93 , original number is 0 -> changed number is 2\n",
            "No. 94 , original number is 2 -> changed number is 1\n",
            "No. 97 , original number is 1 -> changed number is 3\n",
            "No. 98 , original number is 0 -> changed number is 1\n",
            "changed correctlly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM3OSjUWEPH3"
      },
      "source": [
        "##教師ラベルをone-hotに変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHvnUv6KDty_"
      },
      "source": [
        "Y_train = tf.keras.utils.to_categorical(Y_train, 4)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, 4)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAjtSgxaGvBz"
      },
      "source": [
        "# 学習開始"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP3JzbydcYRv"
      },
      "source": [
        "def fix_loss_text(original):\n",
        "  result = re.sub(r\"<tensorflow\\.python\\.keras\\.losses\\.\", \"\", str(original))\n",
        "  result = re.sub(r\"\\sobject.+\", \"\", result)\n",
        "  return result"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZQGLjvFcLRA"
      },
      "source": [
        "used_losses_set = []\n",
        "for each_loss in learningDict[\"compared_losses\"]:\n",
        "  used_losses_set.append(fix_loss_text(each_loss))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXCHuDWpGxz-",
        "outputId": "cb9cc0b4-13e0-44e8-e9d7-57b8034b3613"
      },
      "source": [
        "%%time\n",
        "obj_video_format = video_format()\n",
        "all_histories = [] # append EXPERIMENTS_NUMBER * used losses size\n",
        "\n",
        "start_time = time.time()\n",
        "for j in range(EXPERIMENTS_NUMBER):\n",
        "  seed_in_roop = seed + j\n",
        "  np.random.seed(seed_in_roop)\n",
        "  tf.random.set_seed(seed_in_roop)\n",
        "  print(\"runnng...\")\n",
        "\n",
        "  roop_histories = [] # append used losses size\n",
        "  for i, each_loss in enumerate(learningDict[\"compared_losses\"]):\n",
        "\n",
        "    # 通知\n",
        "    all_loop_counter = str(j * len(learningDict[\"compared_losses\"]) + (i + 1))\n",
        "    all_loop_number = str(EXPERIMENTS_NUMBER * len(learningDict[\"compared_losses\"]))\n",
        "    accumulation_time = str(datetime.timedelta(seconds=(time.time() - start_time)))\n",
        "    start_massage = \"Try the \" + all_loop_counter + \"/\" + all_loop_number + \" loop\\n\"\n",
        "    start_massage += \"The accumulation time is \" + str(accumulation_time) + \"\\n\"\n",
        "    start_massage += \"Current used loss function is [\" + fix_loss_text(each_loss) + \"] = \" + str(i+1) +  \"/\" + str(len(learningDict[\"compared_losses\"]))\n",
        "\n",
        "    print(start_massage)\n",
        "    send_line_notify(start_massage)\n",
        "\n",
        "    try:\n",
        "      # モデル構築\n",
        "      model = make_model(obj_video_format)\n",
        "      model.compile(\n",
        "            optimizer=compile_optimizer(),\n",
        "            loss=each_loss,\n",
        "            metrics=['acc'])\n",
        "      # 実行\n",
        "      \n",
        "      history = model.fit(\n",
        "            X_train, Y_train,\n",
        "            validation_data=(X_test, Y_test),\n",
        "            batch_size=learningDict[\"theWay\"][\"batch_size\"],\n",
        "            epochs=learningDict[\"theWay\"][\"epochs\"]\n",
        "            # verbose=0\n",
        "            )\n",
        "    except KeyboardInterrupt: \n",
        "      print(\"\\n\\nProcessing the KeyboardInterrupt\")\n",
        "\n",
        "    else:\n",
        "      roop_histories.append(history)\n",
        "      finish_massage = \"Complete.\"\n",
        "      print(finish_massage)\n",
        "      send_line_notify(finish_massage)\n",
        "    finally:\n",
        "      del model\n",
        "      keras.backend.clear_session()\n",
        "      gc.collect()\n",
        "      sleep(10)\n",
        "      print(\" and the model is erased.\")\n",
        "\n",
        "  #/for i\n",
        "  all_histories.append(roop_histories)\n",
        "\n",
        "#/for j\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start experiment in the No.1 loop.\n",
            "also assigned[ 20201218 ]as the seed. (the format is integer).\n",
            "used loss functions 3 is : ['CategoricalCrossentropy', 'MeanSquaredError', 'MeanAbsoluteError']\n",
            "runnng...\n",
            "Try the 1/18loop\n",
            "The accumulation time is :0:00:00.000424\n",
            "Current used loss function is :CategoricalCrossentropy=1/3\n",
            "sgd is used as a optimizer\n",
            "Epoch 1/128\n",
            "10/10 [==============================] - 8s 163ms/step - loss: 1.6303 - acc: 0.2265 - val_loss: 1.3830 - val_acc: 0.3700\n",
            "Epoch 2/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3877 - acc: 0.2385 - val_loss: 1.3860 - val_acc: 0.2100\n",
            "Epoch 3/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3851 - acc: 0.2549 - val_loss: 1.5838 - val_acc: 0.1700\n",
            "Epoch 4/128\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 1.4250 - acc: 0.2495 - val_loss: 1.3885 - val_acc: 0.2100\n",
            "Epoch 5/128\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 1.3841 - acc: 0.2742 - val_loss: 1.3913 - val_acc: 0.2200\n",
            "Epoch 6/128\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 1.3844 - acc: 0.2641 - val_loss: 1.3879 - val_acc: 0.2100\n",
            "Epoch 7/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3880 - acc: 0.2529 - val_loss: 1.3927 - val_acc: 0.2100\n",
            "Epoch 8/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3878 - acc: 0.2303 - val_loss: 1.3949 - val_acc: 0.2100\n",
            "Epoch 9/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3848 - acc: 0.2531 - val_loss: 1.3937 - val_acc: 0.2100\n",
            "Epoch 10/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3838 - acc: 0.2646 - val_loss: 1.3904 - val_acc: 0.2100\n",
            "Epoch 11/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3807 - acc: 0.2601 - val_loss: 1.3822 - val_acc: 0.2100\n",
            "Epoch 12/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3777 - acc: 0.3303 - val_loss: 1.3943 - val_acc: 0.1700\n",
            "Epoch 13/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3873 - acc: 0.2506 - val_loss: 1.3962 - val_acc: 0.1700\n",
            "Epoch 14/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3874 - acc: 0.2543 - val_loss: 1.3990 - val_acc: 0.2200\n",
            "Epoch 15/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3840 - acc: 0.2607 - val_loss: 1.4010 - val_acc: 0.2100\n",
            "Epoch 16/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3834 - acc: 0.2715 - val_loss: 1.4011 - val_acc: 0.2100\n",
            "Epoch 17/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3873 - acc: 0.2391 - val_loss: 1.3909 - val_acc: 0.2100\n",
            "Epoch 18/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3886 - acc: 0.2533 - val_loss: 1.3970 - val_acc: 0.2100\n",
            "Epoch 19/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3855 - acc: 0.2679 - val_loss: 1.3998 - val_acc: 0.2200\n",
            "Epoch 20/128\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 1.3812 - acc: 0.2765 - val_loss: 1.4016 - val_acc: 0.2100\n",
            "Epoch 21/128\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 1.3870 - acc: 0.2577 - val_loss: 1.3997 - val_acc: 0.2100\n",
            "Epoch 22/128\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 1.3858 - acc: 0.2532 - val_loss: 1.3966 - val_acc: 0.2100\n",
            "Epoch 23/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3705 - acc: 0.3179 - val_loss: 1.3949 - val_acc: 0.2100\n",
            "Epoch 24/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.2902 - acc: 0.3402 - val_loss: 1.3697 - val_acc: 0.4100\n",
            "Epoch 25/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.1857 - acc: 0.4585 - val_loss: 1.4011 - val_acc: 0.1700\n",
            "Epoch 26/128\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 1.3899 - acc: 0.2427 - val_loss: 1.4061 - val_acc: 0.2100\n",
            "Epoch 27/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3785 - acc: 0.2880 - val_loss: 1.4429 - val_acc: 0.2100\n",
            "Epoch 28/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3903 - acc: 0.3283 - val_loss: 1.3894 - val_acc: 0.2600\n",
            "Epoch 29/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3803 - acc: 0.3523 - val_loss: 1.4207 - val_acc: 0.2300\n",
            "Epoch 30/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 2.0075 - acc: 0.2829 - val_loss: 1.3974 - val_acc: 0.1700\n",
            "Epoch 31/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3902 - acc: 0.2250 - val_loss: 1.3964 - val_acc: 0.1700\n",
            "Epoch 32/128\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 1.3857 - acc: 0.2593 - val_loss: 1.3956 - val_acc: 0.2000\n",
            "Epoch 33/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3817 - acc: 0.3682 - val_loss: 1.3769 - val_acc: 0.2600\n",
            "Epoch 34/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3639 - acc: 0.3151 - val_loss: 1.3804 - val_acc: 0.3200\n",
            "Epoch 35/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3708 - acc: 0.3190 - val_loss: 1.3740 - val_acc: 0.2200\n",
            "Epoch 36/128\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 1.3524 - acc: 0.2709 - val_loss: 1.3947 - val_acc: 0.1700\n",
            "Epoch 37/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3892 - acc: 0.2518 - val_loss: 1.3949 - val_acc: 0.1700\n",
            "Epoch 38/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3846 - acc: 0.2707 - val_loss: 1.3968 - val_acc: 0.1700\n",
            "Epoch 39/128\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 1.3866 - acc: 0.2564 - val_loss: 1.3975 - val_acc: 0.1700\n",
            "Epoch 40/128\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 1.3865 - acc: 0.2370 - val_loss: 1.3967 - val_acc: 0.1600\n",
            "Epoch 41/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3836 - acc: 0.2639 - val_loss: 1.3972 - val_acc: 0.1700\n",
            "Epoch 42/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3864 - acc: 0.2472 - val_loss: 1.3974 - val_acc: 0.1700\n",
            "Epoch 43/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3848 - acc: 0.2828 - val_loss: 1.3984 - val_acc: 0.1700\n",
            "Epoch 44/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3853 - acc: 0.2364 - val_loss: 1.3988 - val_acc: 0.1600\n",
            "Epoch 45/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3822 - acc: 0.2930 - val_loss: 1.3960 - val_acc: 0.1700\n",
            "Epoch 46/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3786 - acc: 0.3339 - val_loss: 1.3892 - val_acc: 0.2200\n",
            "Epoch 47/128\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 1.3576 - acc: 0.4095 - val_loss: 1.3458 - val_acc: 0.4600\n",
            "Epoch 48/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.4017 - acc: 0.3647 - val_loss: 1.3975 - val_acc: 0.1700\n",
            "Epoch 49/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3845 - acc: 0.2671 - val_loss: 1.3996 - val_acc: 0.1700\n",
            "Epoch 50/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3837 - acc: 0.2829 - val_loss: 1.3981 - val_acc: 0.1700\n",
            "Epoch 51/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3856 - acc: 0.2409 - val_loss: 1.3995 - val_acc: 0.2100\n",
            "Epoch 52/128\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 1.3864 - acc: 0.2493 - val_loss: 1.3968 - val_acc: 0.2200\n",
            "Epoch 53/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3860 - acc: 0.2845 - val_loss: 1.3955 - val_acc: 0.2100\n",
            "Epoch 54/128\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 1.3850 - acc: 0.2439 - val_loss: 1.3967 - val_acc: 0.1700\n",
            "Epoch 55/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3870 - acc: 0.2473 - val_loss: 1.3974 - val_acc: 0.1700\n",
            "Epoch 56/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3876 - acc: 0.2595 - val_loss: 1.3955 - val_acc: 0.2100\n",
            "Epoch 57/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3823 - acc: 0.2603 - val_loss: 1.3714 - val_acc: 0.3300\n",
            "Epoch 58/128\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 1.4012 - acc: 0.2321 - val_loss: 1.3975 - val_acc: 0.2200\n",
            "Epoch 59/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3877 - acc: 0.2331 - val_loss: 1.3950 - val_acc: 0.2100\n",
            "Epoch 60/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3858 - acc: 0.2544 - val_loss: 1.3957 - val_acc: 0.2100\n",
            "Epoch 61/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3859 - acc: 0.2364 - val_loss: 1.3967 - val_acc: 0.2100\n",
            "Epoch 62/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3878 - acc: 0.2707 - val_loss: 1.3961 - val_acc: 0.2100\n",
            "Epoch 63/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3838 - acc: 0.2993 - val_loss: 1.3982 - val_acc: 0.2100\n",
            "Epoch 64/128\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 1.3822 - acc: 0.2511 - val_loss: 1.4008 - val_acc: 0.2100\n",
            "Epoch 65/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3882 - acc: 0.2514 - val_loss: 1.3993 - val_acc: 0.2100\n",
            "Epoch 66/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3829 - acc: 0.2879 - val_loss: 1.3990 - val_acc: 0.2100\n",
            "Epoch 67/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3869 - acc: 0.2544 - val_loss: 1.3974 - val_acc: 0.2100\n",
            "Epoch 68/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3812 - acc: 0.2869 - val_loss: 1.3979 - val_acc: 0.2100\n",
            "Epoch 69/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3861 - acc: 0.2361 - val_loss: 1.3968 - val_acc: 0.2100\n",
            "Epoch 70/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3862 - acc: 0.2684 - val_loss: 1.3986 - val_acc: 0.2100\n",
            "Epoch 71/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3851 - acc: 0.2526 - val_loss: 1.3968 - val_acc: 0.2100\n",
            "Epoch 72/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3851 - acc: 0.2657 - val_loss: 1.3972 - val_acc: 0.2100\n",
            "Epoch 73/128\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 1.3824 - acc: 0.2756 - val_loss: 1.3965 - val_acc: 0.2100\n",
            "Epoch 74/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3864 - acc: 0.2715 - val_loss: 1.3949 - val_acc: 0.2100\n",
            "Epoch 75/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3876 - acc: 0.2473 - val_loss: 1.3950 - val_acc: 0.1700\n",
            "Epoch 76/128\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 1.3838 - acc: 0.2639 - val_loss: 1.3970 - val_acc: 0.1700\n",
            "Epoch 77/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3881 - acc: 0.2362 - val_loss: 1.3963 - val_acc: 0.1700\n",
            "Epoch 78/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3858 - acc: 0.2522 - val_loss: 1.3976 - val_acc: 0.1700\n",
            "Epoch 79/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3847 - acc: 0.2722 - val_loss: 1.3974 - val_acc: 0.1700\n",
            "Epoch 80/128\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 1.3876 - acc: 0.2328 - val_loss: 1.3984 - val_acc: 0.1700\n",
            "Epoch 81/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 1.3836 - acc: 0.2971 - val_loss: 1.4008 - val_acc: 0.1700\n",
            "Epoch 82/128\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 1.3877 - acc: 0.2413 - val_loss: 1.4000 - val_acc: 0.1700\n",
            "Epoch 83/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3832 - acc: 0.2673 - val_loss: 1.4006 - val_acc: 0.1900\n",
            "Epoch 84/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3791 - acc: 0.2512 - val_loss: 1.3984 - val_acc: 0.2100\n",
            "Epoch 85/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3852 - acc: 0.2445 - val_loss: 1.3917 - val_acc: 0.2000\n",
            "Epoch 86/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.3785 - acc: 0.2859 - val_loss: 1.3892 - val_acc: 0.2000\n",
            "Epoch 87/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.3807 - acc: 0.3055 - val_loss: 1.3787 - val_acc: 0.2200\n",
            "Epoch 88/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.3643 - acc: 0.3202 - val_loss: 1.3583 - val_acc: 0.2300\n",
            "Epoch 89/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.2920 - acc: 0.3967 - val_loss: 1.3606 - val_acc: 0.2800\n",
            "Epoch 90/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.1882 - acc: 0.4659 - val_loss: 1.4531 - val_acc: 0.3500\n",
            "Epoch 91/128\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 1.0354 - acc: 0.5095 - val_loss: 1.7773 - val_acc: 0.4400\n",
            "Epoch 92/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.8589 - acc: 0.5738 - val_loss: 2.2917 - val_acc: 0.3200\n",
            "Epoch 93/128\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 0.7977 - acc: 0.5715 - val_loss: 2.7969 - val_acc: 0.4100\n",
            "Epoch 94/128\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 1.2176 - acc: 0.4427 - val_loss: 1.5248 - val_acc: 0.2300\n",
            "Epoch 95/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.2246 - acc: 0.4281 - val_loss: 2.1462 - val_acc: 0.2900\n",
            "Epoch 96/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 1.0224 - acc: 0.5287 - val_loss: 1.9181 - val_acc: 0.3200\n",
            "Epoch 97/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.9360 - acc: 0.5190 - val_loss: 2.3099 - val_acc: 0.3600\n",
            "Epoch 98/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.7622 - acc: 0.5920 - val_loss: 2.9286 - val_acc: 0.3900\n",
            "Epoch 99/128\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.6469 - acc: 0.6724 - val_loss: 3.3673 - val_acc: 0.4400\n",
            "Epoch 100/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.5899 - acc: 0.6878 - val_loss: 5.7493 - val_acc: 0.3300\n",
            "Epoch 101/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 1.7191 - acc: 0.3224 - val_loss: 1.5064 - val_acc: 0.3300\n",
            "Epoch 102/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.4792 - acc: 0.2443 - val_loss: 1.3656 - val_acc: 0.3800\n",
            "Epoch 103/128\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 1.3342 - acc: 0.3703 - val_loss: 1.4302 - val_acc: 0.4200\n",
            "Epoch 104/128\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 1.1670 - acc: 0.5142 - val_loss: 1.3467 - val_acc: 0.4000\n",
            "Epoch 105/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 1.0467 - acc: 0.4842 - val_loss: 1.6993 - val_acc: 0.4500\n",
            "Epoch 106/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.8270 - acc: 0.5885 - val_loss: 2.2170 - val_acc: 0.5100\n",
            "Epoch 107/128\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.7171 - acc: 0.5947 - val_loss: 2.9665 - val_acc: 0.3900\n",
            "Epoch 108/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.7396 - acc: 0.5984 - val_loss: 2.0570 - val_acc: 0.3600\n",
            "Epoch 109/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.7505 - acc: 0.6541 - val_loss: 2.9514 - val_acc: 0.4600\n",
            "Epoch 110/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.5225 - acc: 0.7502 - val_loss: 2.9022 - val_acc: 0.3700\n",
            "Epoch 111/128\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.5139 - acc: 0.7162 - val_loss: 4.2674 - val_acc: 0.4000\n",
            "Epoch 112/128\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.4287 - acc: 0.7564 - val_loss: 3.9397 - val_acc: 0.5000\n",
            "Epoch 113/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.4100 - acc: 0.8337 - val_loss: 2.5981 - val_acc: 0.4900\n",
            "Epoch 114/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.5866 - acc: 0.6976 - val_loss: 2.9168 - val_acc: 0.5100\n",
            "Epoch 115/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.4790 - acc: 0.6824 - val_loss: 3.9719 - val_acc: 0.5000\n",
            "Epoch 116/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.3541 - acc: 0.8472 - val_loss: 5.3770 - val_acc: 0.4600\n",
            "Epoch 117/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2642 - acc: 0.8947 - val_loss: 5.9546 - val_acc: 0.4600\n",
            "Epoch 118/128\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.3207 - acc: 0.8815 - val_loss: 7.3273 - val_acc: 0.3400\n",
            "Epoch 119/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.9255 - acc: 0.6211 - val_loss: 2.3689 - val_acc: 0.4500\n",
            "Epoch 120/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.8355 - acc: 0.5917 - val_loss: 3.8039 - val_acc: 0.4500\n",
            "Epoch 121/128\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.8212 - acc: 0.6075 - val_loss: 2.7217 - val_acc: 0.2900\n",
            "Epoch 122/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.6508 - acc: 0.6881 - val_loss: 6.3331 - val_acc: 0.3500\n",
            "Epoch 123/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.7378 - acc: 0.6565 - val_loss: 5.2996 - val_acc: 0.3500\n",
            "Epoch 124/128\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.4866 - acc: 0.7730 - val_loss: 9.5927 - val_acc: 0.4800\n",
            "Epoch 125/128\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 1.4693 - acc: 0.5099 - val_loss: 2.5193 - val_acc: 0.3100\n",
            "Epoch 126/128\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.8956 - acc: 0.5454"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCUgTvVNE2V1"
      },
      "source": [
        "## @学習可視化（history を一つだけ見る）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "237Plt6pA82q"
      },
      "source": [
        "IO = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypG238EdgVWy"
      },
      "source": [
        "now_time = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "today = now_time.strftime('%m%d')\n",
        "\n",
        "print(today)\n",
        "def plot_learning(history, experiment_name=\"No name\"):\n",
        "  HEIGHT = 1\n",
        "  WIDTH = 2\n",
        "  rate = 5.0\n",
        "  WpH_rate = 1.5\n",
        "  fig = plt.figure(figsize=(WIDTH*rate*WpH_rate, HEIGHT*rate))\n",
        "  plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
        "\n",
        "  LOSS = fig.add_subplot(HEIGHT, WIDTH, 1) # loss, val_loss\n",
        "  ACC = fig.add_subplot(HEIGHT, WIDTH, 2) # acc, val_acc\n",
        "\n",
        "  # 1,1 loss\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "  loss_props = {\n",
        "        'title' : 'Loss values plot',\n",
        "        'xlabel' : 'epoch',\n",
        "        'ylabel' : 'value'\n",
        "    }\n",
        "  LOSS.set(**loss_props)\n",
        "  LOSS.plot(loss, label='loss', color='blue')\n",
        "  LOSS.plot(val_loss, label='val_loss', color='orange')\n",
        "  LOSS.legend(loc='best')\n",
        "\n",
        "  # 1,2 acc\n",
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "  acc_props = {\n",
        "        'title' : 'Accuracy values plot',\n",
        "        'xlabel' : 'epoch',\n",
        "        'ylabel' : 'value'\n",
        "    }\n",
        "\n",
        "  ACC.set(**acc_props)\n",
        "  ACC.plot(acc, label='acc', color='blue')\n",
        "  ACC.plot(val_acc, label='val_acc', color='orange')\n",
        "  ACC.legend(loc='best')\n",
        "\n",
        "  #save\n",
        "  image_path = path.join(desk, experiment_name+today)\n",
        "  fig.savefig(image_path, bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6YZZhYOBNQY"
      },
      "source": [
        "if IO:\n",
        "  plot_learning(histories[0], \"how_adam_used_for_KTH_in_certain_model\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w57fZL4pkqsy"
      },
      "source": [
        "## @学習可視化データ保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRGHTigrE-6F"
      },
      "source": [
        "if IO:\n",
        "  shelf = '/content/drive/MyDrive/colab'\n",
        "  book = 'tuning_results'\n",
        "  shelf_book = os.path.join(shelf, book)\n",
        "  shelf_book_page = path.join(shelf_book, today)\n",
        "  print(shelf_book_page)\n",
        "  # 保存\n",
        "  if not os.path.exists(shelf_book_page):\n",
        "    os.makedirs(shelf_book_page)\n",
        "\n",
        "  print(\"writing all to a strage now.\")\n",
        "  for each_file in os.listdir(desk):\n",
        "    if re.match(r\"\\..*\", each_file,):\n",
        "      pass\n",
        "    elif re.match(r\".*\\.png\", each_file,):\n",
        "      print(\"->\", each_file)\n",
        "      shutil.copy2(each_file, shelf_book_page)\n",
        "    else:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLC1pmB3FJQy"
      },
      "source": [
        "# 学習結果保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9gjkqpp5bql"
      },
      "source": [
        "now_time = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "today = now_time.strftime('%m%d')\n",
        "\n",
        "for key_loss, each_loss in enumerate(used_losses_set):\n",
        "  print(each_loss)\n",
        "  for key_experient_number, each_experiment in enumerate(all_histories):\n",
        "    print(\"   \", end=\"\")\n",
        "    print(\"experient_number :\", key_experient_number)\n",
        "    each_history = all_histories[key_experient_number][key_loss]\n",
        "    hist_df = pd.DataFrame(each_history.history)\n",
        "\n",
        "    name = \"KTH\" + \".\"\n",
        "    name = name + str(LABEL_NOISE_RATE) + \".\"\n",
        "    name = name + each_loss + \".\"\n",
        "    name = name + str(key_experient_number) + \".\"\n",
        "    name = name + today\n",
        "    name = name + \".csv\"\n",
        "\n",
        "    hist_df.to_csv(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9WGL2AX-G5b"
      },
      "source": [
        "print(\"all in the desk:\")\n",
        "files_in_the_desk = sorted(os.listdir(desk))\n",
        "for each in files_in_the_desk:\n",
        "  print(\"_____\", end=\"\")\n",
        "  print(each)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7v3R0ur-xYD"
      },
      "source": [
        "directory_name = \"noize=\" + str(LABEL_NOISE_RATE)\n",
        "shelf_path = \"/content/drive/MyDrive/colab/histories/KTH_robust\" \n",
        "shelf_path = path.join(shelf_path, directory_name)\n",
        "\n",
        "if not path.exists(shelf_path):\n",
        "  os.makedirs(shelf_path)\n",
        "else: pass\n",
        "\n",
        "for each_file in files_in_the_desk:\n",
        "  shutil.copy2(each_file, shelf_path)\n",
        "\n",
        "\n",
        "massage = \"Histories are written\\n\"\n",
        "massage += \"So, spent \" + str(datetime.timedelta(seconds=(time.time() - start_time))) + \"in the whole experiments and saving.\"\n",
        "\n",
        "send_line_notify(massage)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}