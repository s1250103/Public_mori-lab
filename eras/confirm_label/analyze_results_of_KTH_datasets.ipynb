{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analyze_results_of_KTH_datasets.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMV5T3E6VHd4BHTnmVCzq4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1250103/Public_mori-lab/blob/confirm_label_noize_for_cm_data/eras/confirm_label/analyze_results_of_KTH_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkB8xKKwvZka"
      },
      "source": [
        "# 環境設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeiF_FkDvWls"
      },
      "source": [
        "## import\n",
        "# file dealing\n",
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "# data dealing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "# process deasing\n",
        "import gc\n",
        "from time import sleep\n",
        "# machine learning (back)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import layers, models, initializers, callbacks\n",
        "# machine learning\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "# others\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import pprint\n",
        "import re\n",
        "from IPython.display import clear_output\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuP6MWHJvBvx"
      },
      "source": [
        "#Historyデータの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00VyH9N3Kl8h",
        "outputId": "d9dca536-7e2c-429f-b5e9-4b99555ed2f8"
      },
      "source": [
        "## gdrive 接続\n",
        "if not path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print(\"Already confirm\")\n",
        "\n",
        "## colab テンポラリディレクトリの作成\n",
        "desk = '/content/desk'\n",
        "if not os.path.exists(desk):\n",
        "  os.mkdir(desk)\n",
        "os.chdir(desk)\n",
        "print(\"Created at /content/desk\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Created at /content/desk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66kEUuVM6IjD",
        "outputId": "0ffb9085-989c-4dca-ecd5-d40200f2c0ca"
      },
      "source": [
        "path_KTH_Histories = \"/content/drive/MyDrive/colab/histories/KTH_robust\"\n",
        "all_history_directories = os.listdir(path_KTH_Histories)\n",
        "all_history_directories = sorted(all_history_directories)\n",
        "print(\"Pick up one key from the below directories\")\n",
        "for key, each_noize_histories in enumerate(all_history_directories):\n",
        "  print(each_noize_histories, \"key:\", key)\n",
        "\n",
        "pick_key = int(input())\n",
        "\n",
        "clear_output()\n",
        "print(\"The key is\", pick_key, \"and\", all_history_directories[pick_key])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The key is 0 and noize=0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKxCIkCEkAKP",
        "outputId": "e4506799-6fba-456d-ca66-4c02449f7d1a"
      },
      "source": [
        "path_pickup_histories = path.join(path_KTH_Histories, all_history_directories[pick_key])\n",
        "\n",
        "each_loss_pattern = r\"KTH\\.(\\d+\\.)+\\w+\"\n",
        "\n",
        "used_losses = []\n",
        "\n",
        "if path.isdir(path_pickup_histories):\n",
        "  print(\"expand\", path_pickup_histories)\n",
        "  partial_histories = os.listdir(path_pickup_histories)\n",
        "  partial_histories = sorted(partial_histories)\n",
        "\n",
        "  count_each = 0\n",
        "  each_loss_header_old = \"\"\n",
        "  some_histories = []\n",
        "  each_loss_histories = []\n",
        "\n",
        "  for i, each_history in enumerate(partial_histories):\n",
        "    each_loss_header = re.match(each_loss_pattern, each_history).group()\n",
        "    each_loss_header = re.sub(r\"KTH(\\.\\d+)+\\.\", '', each_loss_header)\n",
        "\n",
        "    if each_loss_header != each_loss_header_old and each_loss_header_old != \"\": # change different loss\n",
        "      # update for the next loss\n",
        "      some_histories.append(each_loss_histories)\n",
        "      used_losses.append(each_loss_header_old)\n",
        "\n",
        "      count_each = 0\n",
        "      each_loss_histories = []\n",
        "      print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "    else:\n",
        "      pass\n",
        "    \n",
        "    the_history = pd.read_csv(path.join(path_pickup_histories, each_history))\n",
        "    each_loss_histories.append(the_history)\n",
        "      \n",
        "\n",
        "    print(each_loss_header, \"-\", count_each+1, \"@\", i+1)\n",
        "    count_each += 1\n",
        "    each_loss_header_old = each_loss_header\n",
        "\n",
        "    if (i+1) == len(partial_histories): # when the last element\n",
        "      some_histories.append(each_loss_histories)\n",
        "      used_losses.append(each_loss_header)\n",
        "    else:\n",
        "      pass\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "expand /content/drive/MyDrive/colab/histories/KTH_robust/noize=0\n",
            "CategoricalCrossentropy - 1 @ 1\n",
            "CategoricalCrossentropy - 2 @ 2\n",
            "CategoricalCrossentropy - 3 @ 3\n",
            "CategoricalCrossentropy - 4 @ 4\n",
            "CategoricalCrossentropy - 5 @ 5\n",
            "CategoricalCrossentropy - 6 @ 6\n",
            "------------------------------------------------------------------------------\n",
            "MeanAbsoluteError - 1 @ 7\n",
            "MeanAbsoluteError - 2 @ 8\n",
            "MeanAbsoluteError - 3 @ 9\n",
            "MeanAbsoluteError - 4 @ 10\n",
            "MeanAbsoluteError - 5 @ 11\n",
            "MeanAbsoluteError - 6 @ 12\n",
            "------------------------------------------------------------------------------\n",
            "MeanSquaredError - 1 @ 13\n",
            "MeanSquaredError - 2 @ 14\n",
            "MeanSquaredError - 3 @ 15\n",
            "MeanSquaredError - 4 @ 16\n",
            "MeanSquaredError - 5 @ 17\n",
            "MeanSquaredError - 6 @ 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl83XCwze5Tz",
        "outputId": "9b11e90a-ac7c-4830-d2a9-9fb7b15060be"
      },
      "source": [
        "print(\"used in the experiment as loss function :\")\n",
        "print(used_losses)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "used in the experiment as loss function :\n",
            "['CategoricalCrossentropy', 'MeanAbsoluteError', 'MeanSquaredError']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e02kPe2y_vVE"
      },
      "source": [
        "# 選んだノイズに関する実験のすべてのlossとaccを可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGb-RzNgKmOr"
      },
      "source": [
        "noize_rate = all_history_directories[pick_key]\n",
        "noize_rate = str(noize_rate)\n",
        "\n",
        "WIDTH = 8\n",
        "HEIGHT = 10\n",
        "\n",
        "for key_loss, each_loss in enumerate(used_losses):\n",
        "  # 図のインスタンス作成\n",
        "  fig = plt.figure(figsize=(WIDTH, HEIGHT))\n",
        "\n",
        "  ## 図にグラフをプロット\n",
        "  k = 1\n",
        "  rate = 1.5  # プロットのための係数\n",
        "  for row in range(6):\n",
        "    # LOSS part\n",
        "    ## set\n",
        "    LOSS_plt = fig.add_subplot(6, 2, k)\n",
        "    LOSS_plt.set_position([0.3*1*rate, 0.2*row*rate, 0.3, 0.2])\n",
        "    LOSS_plt.set_title(each_loss)\n",
        "    LOSS_plt.set_xlabel('Epochs')\n",
        "    LOSS_plt.set_ylabel('Loss')\n",
        "    ## plot \n",
        "    loss = some_histories[key_loss][row][\"loss\"] \n",
        "    val_loss = some_histories[key_loss][row][\"val_loss\"]\n",
        "    LOSS_plt.plot(loss, label='loss', color='blue') # plot loss\n",
        "    LOSS_plt.plot(val_loss, label='val_loss', color='red') # plot val_loss\n",
        "    LOSS_plt.legend(loc='best')\n",
        "\n",
        "    k+=1\n",
        "\n",
        "    # ACC part\n",
        "    ## set\n",
        "    ACC_plt = fig.add_subplot(6, 2, k)\n",
        "    ACC_plt.set_position([0.3*2*rate, 0.2*row*rate, 0.3, 0.2])\n",
        "    ACC_plt.set_title(each_loss)\n",
        "    ACC_plt.set_xlabel('Epochs')\n",
        "    ACC_plt.set_ylabel('Accuracy')\n",
        "    ## plot \n",
        "    acc = some_histories[key_loss][row][\"acc\"] \n",
        "    val_acc = some_histories[key_loss][row][\"val_acc\"]\n",
        "    ACC_plt.plot(acc, label='loss', color='blue') # plot acc\n",
        "    ACC_plt.plot(val_acc, label='val_loss', color='red') # plot val_loss\n",
        "    ACC_plt.legend(loc='best')\n",
        "    k += 1\n",
        "  \n",
        "  filename = noize_rate + each_loss + \"_six\" + \".png\"\n",
        "  save_path = path.join(desk, filename)\n",
        "  fig.savefig(save_path, bbox_inches='tight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTUGnfCFTWr"
      },
      "source": [
        "# 最終エポックでのval_accを比較して、最も高いものを選ぶ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ7q4xXgLKus"
      },
      "source": [
        "import math"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7_AloYlAV5o",
        "outputId": "7c7b8709-d2d7-40d2-e372-89a8ebe1bdd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_value_key_sets_for_losses = []\n",
        "for key_loss, each_loss in enumerate(used_losses):\n",
        "  print(each_loss)\n",
        "\n",
        "  max_value_for_each_loss = 0\n",
        "  key_for_max_value = 0\n",
        "  each_accumulate = 0\n",
        "  each_accumulate_for_power = 0\n",
        "  for row in range(6):\n",
        "    epochs = len(some_histories[key_loss][row])\n",
        "    print(some_histories[key_loss][row][\"val_acc\"][epochs-1])\n",
        "    # calculate for each sum\n",
        "    each_accumulate += some_histories[key_loss][row][\"val_acc\"][epochs-1]\n",
        "    # calculate for each\n",
        "    each_accumulate_for_power += some_histories[key_loss][row][\"val_acc\"][epochs-1] * some_histories[key_loss][row][\"val_acc\"][epochs-1]\n",
        "\n",
        "\n",
        "    if some_histories[key_loss][row][\"val_acc\"][epochs-1] > max_value_for_each_loss:\n",
        "      max_value_for_each_loss = some_histories[key_loss][row][\"val_acc\"][epochs-1]\n",
        "      key_for_max_value = row\n",
        "      \n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  each_sum = each_accumulate\n",
        "  each_mean = each_sum / 6\n",
        "  each_power_mean = each_accumulate_for_power / 6\n",
        "  each_standard_deviation = math.sqrt(each_power_mean - (each_mean * each_mean))\n",
        "  print(\"For\", each_loss)\n",
        "  print(\"when the key is\", key_for_max_value)\n",
        "  print(\"the max value is\", max_value_for_each_loss)\n",
        "  print(\"the sum value is\", each_sum)\n",
        "  print(\"the mean value is\", each_mean)\n",
        "  print(\"the standard deviation is\", each_standard_deviation, \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "  max_value_key_set = [max_value_for_each_loss, key_for_max_value]\n",
        "  max_value_key_sets_for_losses.append(max_value_key_set)\n",
        "    "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CategoricalCrossentropy\n",
            "0.699999988079071\n",
            "0.6600000262260437\n",
            "0.2199999988079071\n",
            "0.6499999761581421\n",
            "0.2199999988079071\n",
            "0.6299999952316284\n",
            "For CategoricalCrossentropy\n",
            "when the key is 0\n",
            "the max value is 0.699999988079071\n",
            "the sum value is 3.0799999833106995\n",
            "the mean value is 0.5133333305517832\n",
            "the standard deviation is 0.2084599603221825 \n",
            "\n",
            "MeanAbsoluteError\n",
            "0.7400000095367432\n",
            "0.4399999976158142\n",
            "0.7599999904632568\n",
            "0.7599999904632568\n",
            "0.6000000238418579\n",
            "0.7400000095367432\n",
            "For MeanAbsoluteError\n",
            "when the key is 2\n",
            "the max value is 0.7599999904632568\n",
            "the sum value is 4.040000021457672\n",
            "the mean value is 0.6733333369096121\n",
            "the standard deviation is 0.11813363209109733 \n",
            "\n",
            "MeanSquaredError\n",
            "0.7300000190734863\n",
            "0.7699999809265137\n",
            "0.7699999809265137\n",
            "0.7799999713897705\n",
            "0.7599999904632568\n",
            "0.75\n",
            "For MeanSquaredError\n",
            "when the key is 3\n",
            "the max value is 0.7799999713897705\n",
            "the sum value is 4.559999942779541\n",
            "the mean value is 0.7599999904632568\n",
            "the standard deviation is 0.01632991604511815 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3n0YsknFqhK",
        "outputId": "4c00931e-0928-4aa1-dff5-0d6a59e66533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for key_loss, each_loss in enumerate(used_losses):\n",
        "  print(each_loss)\n",
        "  print(\"when the No.\", max_value_key_sets_for_losses[key_loss][1])\n",
        "  print(\"the max value\", max_value_key_sets_for_losses[key_loss][0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CategoricalCrossentropy\n",
            "when the No. 0\n",
            "the max value 0.699999988079071\n",
            "MeanAbsoluteError\n",
            "when the No. 2\n",
            "the max value 0.7599999904632568\n",
            "MeanSquaredError\n",
            "when the No. 3\n",
            "the max value 0.7799999713897705\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}