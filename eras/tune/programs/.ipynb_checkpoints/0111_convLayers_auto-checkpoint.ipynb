{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/s1250103/Public_mori-lab/blob/eras/eras/tune/programs/0111_convLayers_auto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJv5QoBNNxn9"
   },
   "source": [
    "#共通設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7pVngb_1YBOx"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1XXQEFloKtJ"
   },
   "source": [
    "#ツール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EPu0Nt30oGZ9"
   },
   "outputs": [],
   "source": [
    "def beep():\n",
    "  from google.colab import output\n",
    "  output.eval_js('new Audio(\\\n",
    "\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\")\\\n",
    ".play()') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mImM901BtpX0"
   },
   "source": [
    "# モジュールインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fSYRajvAtS_W"
   },
   "outputs": [],
   "source": [
    "# file dealing\n",
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "from google.colab import drive\n",
    "# data dealing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "# process deasing\n",
    "import gc\n",
    "from time import sleep\n",
    "\n",
    "# machine learning (back)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers, models, initializers, callbacks\n",
    "\n",
    "# machine learning\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qbZWFAfoSEv"
   },
   "source": [
    "#ディレクトリ環境設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ba20PBiDApiV"
   },
   "outputs": [],
   "source": [
    "def make_dirStruct():\n",
    "  # gdrive 接続\n",
    "  if not path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "  else:\n",
    "    print(\"Already confirm\")\n",
    "  # colab テンポラリディレクトリの作成\n",
    "  desk = '/content/desk'\n",
    "  if not os.path.exists(desk):\n",
    "    os.mkdir(desk)\n",
    "  os.chdir(desk)\n",
    "  print(\"Created at /content/desk\")\n",
    "  return desk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyAEWeHxBXLB",
    "outputId": "cee8b46c-0742-43a4-d287-f46482c284c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Created at /content/desk\n"
     ]
    }
   ],
   "source": [
    "desk = make_dirStruct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfAtQHN6N--8"
   },
   "source": [
    "# データフォーマットを規定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X4xSyyRpKq3W"
   },
   "outputs": [],
   "source": [
    "class video_format:\n",
    "  name = \"video_format\"\n",
    "  # サンプリングされたCMデータの仕様\n",
    "  playtime = \"15秒\"\n",
    "  displaysize = \"(any, any, RGB)\"\n",
    "  videoformat = \"any\"\n",
    "  # モデルが扱うCMデータ(上のようなデータは、下のように変換される)\n",
    "  HEIGHT = 45\n",
    "  WIDTH = 80\n",
    "  FRAME_SIZE = 30\n",
    "  COLORinfo = 3 # \"RGB\"\n",
    "  FPS = \"2 (FRAME_SIZE / playtime)\" # 定義ではなく上から導かれた値\n",
    "\n",
    "format1 = video_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBa2QGgHVOn4"
   },
   "source": [
    "#データをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYjxmEMpAZU1",
    "outputId": "e40eae79-c315-4513-b909-54bebb6587a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get :  /content/drive/MyDrive/colab/dence1223/normalTrainLabels.npz\n",
      "get :  /content/drive/MyDrive/colab/dence1223/normalTrainVideos.npz\n",
      "get :  /content/drive/MyDrive/colab/dence1223/normalTestLabels.npz\n",
      "get :  /content/drive/MyDrive/colab/dence1223/normalTestVideos.npz\n",
      "CPU times: user 77.7 ms, sys: 414 ms, total: 491 ms\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "# 必要なファイルを'desk'にコピー\n",
    "%%time\n",
    "wants_paths = [\n",
    "'/content/drive/MyDrive/colab/dence1223/normalTrainLabels.npz',\n",
    "'/content/drive/MyDrive/colab/dence1223/normalTrainVideos.npz',\n",
    "'/content/drive/MyDrive/colab/dence1223/normalTestLabels.npz',\n",
    "'/content/drive/MyDrive/colab/dence1223/normalTestVideos.npz'\n",
    "]\n",
    "\n",
    "for want in wants_paths:\n",
    "  if not os.path.exists(os.path.join(desk, os.path.basename(want))):\n",
    "    shutil.copy2(want, desk)\n",
    "    print(\"get : \", want)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z95hdLLJc-VD"
   },
   "outputs": [],
   "source": [
    "# ファイルをメモリにコピー\n",
    "def prepare_data():\n",
    "  # traindata\n",
    "  v = np.load('/content/desk/normalTrainVideos.npz')\n",
    "  l = np.load('/content/desk/normalTrainLabels.npz')\n",
    "\n",
    "  train_videos = [] \n",
    "  train_labels = []\n",
    "  for i in v.files:\n",
    "    train_videos.append(v[i])\n",
    "  for i in l.files:\n",
    "    train_labels.append(l[i])\n",
    "\n",
    "  train_videos = np.array(train_videos)\n",
    "  train_labels = np.array(train_labels)\n",
    "  train_labels = tf.keras.utils.to_categorical(train_labels, 4)\n",
    "\n",
    "  # testdata\n",
    "  v = np.load('/content/desk/normalTestVideos.npz')\n",
    "  l = np.load('/content/desk/normalTestLabels.npz')\n",
    "\n",
    "  test_videos = []\n",
    "  test_labels = []\n",
    "  for i in v.files:\n",
    "    test_videos.append(v[i])\n",
    "  for i in l.files:\n",
    "    test_labels.append(l[i])\n",
    "\n",
    "  test_videos = np.array(test_videos)\n",
    "  test_labels = np.array(test_labels)\n",
    "  test_labels = tf.keras.utils.to_categorical(test_labels, 4)\n",
    "  \n",
    "  return train_videos, train_labels,  test_videos, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "weiihIiWesyF"
   },
   "outputs": [],
   "source": [
    "train_videos, train_labels,  test_videos, test_labels = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62PHow0YW7WT"
   },
   "source": [
    "#学習実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "form",
    "id": "F6JeXdD4PsaV"
   },
   "outputs": [],
   "source": [
    "#@title プロット用モジュール\n",
    "def plot(history, elementsDict, name='tmp'):\n",
    "  HEIGHT = 2\n",
    "  WIDTH = 2\n",
    "\n",
    "  # 下地の用意\n",
    "  fig = plt.figure()\n",
    "  LOSS = fig.add_subplot(HEIGHT, WIDTH, 1)\n",
    "  ACC = fig.add_subplot(HEIGHT, WIDTH, 2)\n",
    "  LOSSDIF = fig.add_subplot(HEIGHT, WIDTH, 3)\n",
    "  LEARNING_OUTLINE = fig.add_subplot(HEIGHT, WIDTH, 4)\n",
    "\n",
    "\n",
    "  plt.subplots_adjust(left=None, bottom=None, right=1.5, top=1.5, wspace=0.5, hspace=0.5)\n",
    "\n",
    "  # 1,1 loss\n",
    "  loss = DataFrame(history.history['loss'])\n",
    "  val_loss = DataFrame(history.history['val_loss'])\n",
    "  loss_props = {\n",
    "        'title' : 'Loss values plot',\n",
    "        'xlabel' : 'epoch',\n",
    "        'ylabel' : 'value'\n",
    "    }\n",
    "  LOSS.set(**loss_props)\n",
    "  LOSS.plot(loss, label='loss', color='blue')\n",
    "  LOSS.plot(val_loss, label='val_loss', color='orange')\n",
    "  LOSS.legend(loc='best')\n",
    "\n",
    "  # 1,2 acc\n",
    "  acc = DataFrame(history.history['acc'])\n",
    "  val_acc = DataFrame(history.history['val_acc'])\n",
    "  acc_props = {\n",
    "        'title' : 'Accuracy values plot',\n",
    "        'xlabel' : 'epoch',\n",
    "        'ylabel' : 'value'\n",
    "    }\n",
    "  ACC.set(**acc_props)\n",
    "  ACC.plot(acc, label='acc', color='blue')\n",
    "  ACC.plot(val_acc, label='val_acc', color='orange')\n",
    "  ACC.legend(loc='best')\n",
    "\n",
    "  #2,1 loss.diff\n",
    "  loss_diff_props = {\n",
    "      'title' : 'Derivative values plot',\n",
    "      # 'xlabel' : 'epoch',\n",
    "      'ylabel' : 'value'\n",
    "  }\n",
    "  LOSSDIF.set(**loss_diff_props)\n",
    "  LOSSDIF.plot(loss.diff(), label='loss_diff', color='blue')\n",
    "  LOSSDIF.plot(val_loss.diff(), label='val_loss_diff', color='orange')\n",
    "  LOSSDIF.legend(loc='best')\n",
    "\n",
    "  # 2,2 learning outline\n",
    "  tmp = {\n",
    "      'title' : 'learning outline',\n",
    "      'xticks' : ([]),\n",
    "      'yticks' : ([]),\n",
    "  }\n",
    "\n",
    "  LEARNING_OUTLINE.set(**tmp)\n",
    "  LEARNING_OUTLINE.text(0.1, 0.5, modelOutline(elementsDict), size=10)\n",
    "\n",
    "  #save\n",
    "  path_image = os.path.join(desk, name)\n",
    "  fig.savefig(path_image, bbox_inches='tight')\n",
    "\n",
    "def modelOutline(elementsDict):\n",
    "  sentence = \"\"\n",
    "\n",
    "  for each in elementsDict.keys():\n",
    "    if isinstance(elementsDict[each], int) or isinstance(elementsDict[each], float):\n",
    "      sentence = sentence + each + \" : \" + str(elementsDict[each]) + \"\\n\"\n",
    "      # print(str(elementsDict[each]))\n",
    "    else:\n",
    "      sentence = sentence + each + \" : \" + get_var_name(elementsDict[each]) + \"\\n\"\n",
    "      # print(get_var_name(elementsDict[each]))\n",
    "  return sentence\n",
    "\n",
    "def get_var_name(var):\n",
    "    for k,v in globals().items():\n",
    "        if id(v) == id(var):\n",
    "            name=k\n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-fO9KmJcJo8"
   },
   "source": [
    "実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yX4am7r0cPbC"
   },
   "outputs": [],
   "source": [
    "seed = 20201218\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "learningDict = {\n",
    "    \"learning_rate\" : 1e-7,\n",
    "    \"batch_size\" : 32,\n",
    "    \"epochs\" : 1024,\n",
    "}\n",
    "\n",
    "# 最適化一覧\n",
    "adam = keras.optimizers.Adam(\n",
    "    lr=learningDict[\"learning_rate\"], beta_1=0.9, beta_2=0.999)\n",
    "# 誤差関数一覧\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "vZwi2x9IexH5",
    "outputId": "b6672e17-7934-42a5-f929-335fb4941e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n",
      "Complete.\n",
      "CPU times: user 37min 3s, sys: 13min 24s, total: 50min 27s\n",
      "Wall time: 1h 13min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "useLosses = [cce, mse]\n",
    "histories = []\n",
    "\n",
    "# 繰り返しの条件\n",
    "for loss in useLosses:\n",
    "  addDict = {\n",
    "      \"optimizer\" : adam,\n",
    "      \"loss\" : loss\n",
    "  }\n",
    "  elementsDict = {}\n",
    "  elementsDict.update(learningDict)\n",
    "  elementsDict.update(addDict)\n",
    "\n",
    "  # モデル作成\n",
    "  model = models.Sequential()\n",
    "  # 入力層\n",
    "  model.add(\n",
    "      layers.Reshape(\n",
    "          (format1.FRAME_SIZE,\n",
    "          format1.HEIGHT,\n",
    "          format1.WIDTH,\n",
    "          format1.COLORinfo),\n",
    "          input_shape=(format1.FRAME_SIZE * format1.HEIGHT * format1.WIDTH * format1.COLORinfo,),\n",
    "          name='ENTRANCE' )\n",
    "  )\n",
    "\n",
    "  ## 畳み込み0\n",
    "  model.add(\n",
    "      layers.Conv3D(\n",
    "          filters=32,\n",
    "          kernel_size=(2, 3, 3),\n",
    "          strides=(1, 1, 1),\n",
    "          padding='same',\n",
    "          activation='relu',\n",
    "          name='conv0'))\n",
    "  ## pool0\n",
    "  model.add(\n",
    "      layers.MaxPooling3D(pool_size=(2, 3, 3), name='pool0'))\n",
    "\n",
    "  ## 畳み込み1\n",
    "  model.add(\n",
    "      layers.Conv3D(\n",
    "          filters=64,\n",
    "          kernel_size=(2, 3, 3),\n",
    "          strides=(1, 1, 1),\n",
    "          padding='same',\n",
    "          activation='relu',\n",
    "          name='conv1'))\n",
    "\n",
    "  ## 全結合0\n",
    "  model.add(\n",
    "      layers.Flatten(name='pipe'),\n",
    "  )\n",
    "  model.add(\n",
    "      layers.Dense(1024,\n",
    "        activation='relu',\n",
    "        name='DAM' ),\n",
    "  )\n",
    "  # 出力層\n",
    "  model.add(\n",
    "      layers.Dense(4, activation='softmax', name='WATERSUPPLY')\n",
    "  )\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=elementsDict[\"optimizer\"],\n",
    "      loss=elementsDict[\"loss\"],\n",
    "      metrics=['acc', cce])\n",
    "\n",
    "  # 実行\n",
    "  history = model.fit(\n",
    "        train_videos, train_labels,\n",
    "        validation_data=(test_videos, test_labels),\n",
    "        batch_size=elementsDict[\"batch_size\"],\n",
    "        epochs=elementsDict[\"epochs\"],\n",
    "        verbose=0\n",
    "        )\n",
    "\n",
    "  print(\"Complete.\")\n",
    "\n",
    "  # プロット \n",
    "  # plot(history, elementsDict)\n",
    "\n",
    "  histories.append(history)\n",
    "\n",
    "  # 消去\n",
    "  sleep(10)\n",
    "  del model\n",
    "  keras.backend.clear_session()\n",
    "  gc.collect()\n",
    "\n",
    "\n",
    "beep()\n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "dt_now_jst = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
    "now = dt_now_jst.strftime('%m%d-%H%M')\n",
    "csvs = []\n",
    "\n",
    "# cce\n",
    "hist_df = pd.DataFrame(histories[0].history)\n",
    "name = now + \"cce.csv\"\n",
    "hist_df.to_csv(name)\n",
    "csvs.append(name)\n",
    "# mse\n",
    "hist_df = pd.DataFrame(histories[1].history)\n",
    "name = now + \"mse.csv\"\n",
    "hist_df.to_csv(name)\n",
    "csvs.append(name)\n",
    "\n",
    "\n",
    "shelf = '/content/drive/MyDrive/colab'\n",
    "book = 'histories'\n",
    "shelf_book = os.path.join(shelf, book)\n",
    "if not os.path.exists(shelf_book):\n",
    "  os.mkdir(shelf_book)\n",
    "# 保存\n",
    "for one in csvs:\n",
    "  print(os.path.join(desk, one))\n",
    "  shutil.copy2(one, shelf_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSA5z9z51_Dv"
   },
   "source": [
    "読む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xEPht8j41-tZ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('history.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMZJORfLoNCcxVT75HdjICC",
   "include_colab_link": true,
   "name": "0111.convLayers_auto.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
