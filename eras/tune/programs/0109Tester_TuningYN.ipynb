{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0109Tester_TuningYN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdTf7EvU8C56sIlw+x+Yc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1250103/Public_mori-lab/blob/eras/eras/tune/programs/0109Tester_TuningYN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJv5QoBNNxn9"
      },
      "source": [
        "#共通設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pVngb_1YBOx"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1XXQEFloKtJ"
      },
      "source": [
        "#ツール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPu0Nt30oGZ9"
      },
      "source": [
        "def beep():\n",
        "  from google.colab import output\n",
        "  output.eval_js('new Audio(\\\n",
        "\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\")\\\n",
        ".play()') "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mImM901BtpX0"
      },
      "source": [
        "# モジュールインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSYRajvAtS_W"
      },
      "source": [
        "# file dealing\n",
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "# data dealing\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "# process deasing\n",
        "import gc\n",
        "from time import sleep\n",
        "\n",
        "# machine learning (back)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import layers, models, initializers, callbacks\n",
        "\n",
        "# machine learning\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qbZWFAfoSEv"
      },
      "source": [
        "#ディレクトリ環境設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba20PBiDApiV"
      },
      "source": [
        "def make_dirStruct():\n",
        "  # gdrive 接続\n",
        "  if not path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "  else:\n",
        "    print(\"Already confirm\")\n",
        "  # colab テンポラリディレクトリの作成\n",
        "  desk = '/content/desk'\n",
        "  if not os.path.exists(desk):\n",
        "    os.mkdir(desk)\n",
        "  os.chdir(desk)\n",
        "  print(\"Created at /content/desk\")\n",
        "  return desk"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyAEWeHxBXLB",
        "outputId": "139945d8-3580-4055-aa27-0ce0c24faff8"
      },
      "source": [
        "desk = make_dirStruct()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already confirm\n",
            "Created at /content/desk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfAtQHN6N--8"
      },
      "source": [
        "# データフォーマットを規定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4xSyyRpKq3W"
      },
      "source": [
        "class video_format:\n",
        "  name = \"video_format\"\n",
        "  # サンプリングされたCMデータの仕様\n",
        "  playtime = \"15秒\"\n",
        "  displaysize = \"(any, any, RGB)\"\n",
        "  videoformat = \"any\"\n",
        "  # モデルが扱うCMデータ(上のようなデータは、下のように変換される)\n",
        "  HEIGHT = 45\n",
        "  WIDTH = 80\n",
        "  FRAME_SIZE = 30\n",
        "  COLORinfo = 3 # \"RGB\"\n",
        "  FPS = \"2 (FRAME_SIZE / playtime)\" # 定義ではなく上から導かれた値\n",
        "\n",
        "format1 = video_format()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBa2QGgHVOn4"
      },
      "source": [
        "#データをインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYjxmEMpAZU1",
        "cellView": "code"
      },
      "source": [
        "# 必要なファイルを'desk'にコピー\n",
        "%%time\n",
        "wants_paths = [\n",
        "'/content/drive/MyDrive/colab/dence1223/normalTrainLabels.npz',\n",
        "'/content/drive/MyDrive/colab/dence1223/normalTrainVideos.npz',\n",
        "'/content/drive/MyDrive/colab/dence1223/normalTestLabels.npz',\n",
        "'/content/drive/MyDrive/colab/dence1223/normalTestVideos.npz'\n",
        "]\n",
        "\n",
        "for want in wants_paths:\n",
        "  if not os.path.exists(os.path.join(desk, os.path.basename(want))):\n",
        "    shutil.copy2(want, desk)\n",
        "    print(\"get : \", want)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z95hdLLJc-VD"
      },
      "source": [
        "# ファイルをメモリにコピー\n",
        "def prepare_data():\n",
        "  # traindata\n",
        "  v = np.load('/content/desk/normalTrainVideos.npz')\n",
        "  l = np.load('/content/desk/normalTrainLabels.npz')\n",
        "\n",
        "  train_videos = [] \n",
        "  train_labels = []\n",
        "  for i in v.files:\n",
        "    train_videos.append(v[i])\n",
        "  for i in l.files:\n",
        "    train_labels.append(l[i])\n",
        "\n",
        "  train_videos = np.array(train_videos)\n",
        "  train_labels = np.array(train_labels)\n",
        "  train_labels = tf.keras.utils.to_categorical(train_labels, 4)\n",
        "\n",
        "  # testdata\n",
        "  v = np.load('/content/desk/normalTestVideos.npz')\n",
        "  l = np.load('/content/desk/normalTestLabels.npz')\n",
        "\n",
        "  test_videos = []\n",
        "  test_labels = []\n",
        "  for i in v.files:\n",
        "    test_videos.append(v[i])\n",
        "  for i in l.files:\n",
        "    test_labels.append(l[i])\n",
        "\n",
        "  test_videos = np.array(test_videos)\n",
        "  test_labels = np.array(test_labels)\n",
        "  test_labels = tf.keras.utils.to_categorical(test_labels, 4)\n",
        "  \n",
        "  return train_videos, train_labels,  test_videos, test_labels"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weiihIiWesyF"
      },
      "source": [
        "train_videos, train_labels,  test_videos, test_labels = prepare_data()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8Fa2FDjVVFi"
      },
      "source": [
        "#モデル作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIF-xwOvu07x"
      },
      "source": [
        "seed = 20201218\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuKPYYfWu5GE"
      },
      "source": [
        "\n",
        "# モデル作成\n",
        "model = models.Sequential()\n",
        "# 入力層\n",
        "model.add(\n",
        "     layers.Reshape(\n",
        "        (format1.FRAME_SIZE,\n",
        "         format1.HEIGHT,\n",
        "         format1.WIDTH,\n",
        "         format1.COLORinfo),\n",
        "        input_shape=(format1.FRAME_SIZE * format1.HEIGHT * format1.WIDTH * format1.COLORinfo,),\n",
        "        name='ENTRANCE' )\n",
        ")\n",
        "\n",
        "## 畳み込み0\n",
        "model.add(\n",
        "    layers.Conv3D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 3, 3),\n",
        "        strides=(1, 1, 1),\n",
        "        padding='same',\n",
        "        activation='relu',\n",
        "        name='conv0'))\n",
        "## pool0\n",
        "model.add(\n",
        "    layers.MaxPooling3D(pool_size=(2, 3, 3), name='pool0'))\n",
        "\n",
        "## 畳み込み1\n",
        "model.add(\n",
        "    layers.Conv3D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3, 3),\n",
        "        strides=(1, 1, 1),\n",
        "        padding='same',\n",
        "        activation='relu',\n",
        "        name='conv1'))\n",
        "\n",
        "## 全結合0\n",
        "model.add(\n",
        "    layers.Flatten(name='pipe'),\n",
        ")\n",
        "model.add(\n",
        "    layers.Dense(1024,\n",
        "      activation='relu',\n",
        "      name='DAM' ),\n",
        ")\n",
        "# 出力層\n",
        "model.add(\n",
        "    layers.Dense(4, activation='softmax', name='WATERSUPPLY')\n",
        ")\n",
        "\n",
        "elementsDic = {\n",
        "    \"learning_rate\" : 1e-6,\n",
        "    \"batch_size\" : 32,\n",
        "    \"epochs\" : 2048,\n",
        "}\n",
        "# 最適化一覧\n",
        "adam = keras.optimizers.Adam(\n",
        "    lr=optimizerDict[\"learning_rate\"], beta_1=0.9, beta_2=0.999)\n",
        "# 誤差関数一覧\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# 使うもの\n",
        "addDict = {\n",
        "    \"optimizer\" : adam,\n",
        "    \"loss\" : cce,\n",
        "}\n",
        "elementsDict.update(addDict)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=elementsDict[\"optimizer\"],\n",
        "    loss=elementsDict[\"loss\"],\n",
        "    metrics=['acc', cce])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMDFKtD3uvHx"
      },
      "source": [
        "多分エラー..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrqKqzvC2Otp"
      },
      "source": [
        "seed = 20201218\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "def makeModel():\n",
        "  # モデル作成\n",
        "  model = models.Sequential()\n",
        "  # 入力層\n",
        "  model.add(\n",
        "      layers.Reshape(\n",
        "          (format1.FRAME_SIZE,\n",
        "          format1.HEIGHT,\n",
        "          format1.WIDTH,\n",
        "          format1.COLORinfo),\n",
        "          input_shape=(format1.FRAME_SIZE * format1.HEIGHT * format1.WIDTH * format1.COLORinfo,),\n",
        "          name='ENTRANCE' )\n",
        "  )\n",
        "\n",
        "  ## 畳み込み0\n",
        "  model.add(\n",
        "      layers.Conv3D(\n",
        "          filters=32,\n",
        "          kernel_size=(2, 3, 3),\n",
        "          strides=(1, 1, 1),\n",
        "          padding='same',\n",
        "          activation='relu',\n",
        "          name='conv0'))\n",
        "  ## pool0\n",
        "  model.add(\n",
        "      layers.MaxPooling3D(pool_size=(2, 3, 3), name='pool0'))\n",
        "\n",
        "  ## 畳み込み1\n",
        "  model.add(\n",
        "      layers.Conv3D(\n",
        "          filters=64,\n",
        "          kernel_size=(2, 3, 3),\n",
        "          strides=(1, 1, 1),\n",
        "          padding='same',\n",
        "          activation='relu',\n",
        "          name='conv1'))\n",
        "\n",
        "  ## 全結合0\n",
        "  model.add(\n",
        "      layers.Flatten(name='pipe'),\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(1024,\n",
        "        activation='relu',\n",
        "        name='DAM' ),\n",
        "  )\n",
        "  # 出力層\n",
        "  model.add(\n",
        "      layers.Dense(4, activation='softmax', name='WATERSUPPLY')\n",
        "  )\n",
        "\n",
        "  elementsDict = {\n",
        "      \"learning_rate\" : 1e-7,\n",
        "      \"batch_size\" : 32,\n",
        "      \"epochs\" : 1024,\n",
        "  }\n",
        "  # 最適化一覧\n",
        "  adam = keras.optimizers.Adam(\n",
        "      lr=optimizerDict[\"learning_rate\"], beta_1=0.9, beta_2=0.999)\n",
        "  # 誤差関数一覧\n",
        "  mse = tf.keras.losses.MeanSquaredError()\n",
        "  cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "  # 使うもの\n",
        "  addDict = {\n",
        "      \"optimizer\" : adam,\n",
        "      \"loss\" : cce,\n",
        "  }\n",
        "  elementsDict.update(addDict)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=elementsDict[\"optimizer\"],\n",
        "      loss=elementsDict[\"loss\"],\n",
        "      metrics=['acc', cce])\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62PHow0YW7WT"
      },
      "source": [
        "#学習実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6JeXdD4PsaV"
      },
      "source": [
        "def plot(history, elementsDict, name='tmp'):\n",
        "  HEIGHT = 2\n",
        "  WIDTH = 2\n",
        "\n",
        "  # 下地の用意\n",
        "  fig = plt.figure()\n",
        "  LOSS = fig.add_subplot(HEIGHT, WIDTH, 1)\n",
        "  ACC = fig.add_subplot(HEIGHT, WIDTH, 2)\n",
        "  LOSSDIF = fig.add_subplot(HEIGHT, WIDTH, 3)\n",
        "  LEARNING_OUTLINE = fig.add_subplot(HEIGHT, WIDTH, 4)\n",
        "\n",
        "\n",
        "  plt.subplots_adjust(left=None, bottom=None, right=1.5, top=1.5, wspace=0.5, hspace=0.5)\n",
        "\n",
        "  # 1,1 loss\n",
        "  loss = DataFrame(history.history['loss'])\n",
        "  val_loss = DataFrame(history.history['val_loss'])\n",
        "  loss_props = {\n",
        "        'title' : 'Loss values plot',\n",
        "        'xlabel' : 'epoch',\n",
        "        'ylabel' : 'value'\n",
        "    }\n",
        "  LOSS.set(**loss_props)\n",
        "  LOSS.plot(loss, label='loss', color='blue')\n",
        "  LOSS.plot(val_loss, label='val_loss', color='orange')\n",
        "  LOSS.legend(loc='best')\n",
        "\n",
        "  # 1,2 acc\n",
        "  acc = DataFrame(history.history['acc'])\n",
        "  val_acc = DataFrame(history.history['val_acc'])\n",
        "  acc_props = {\n",
        "        'title' : 'Accuracy values plot',\n",
        "        'xlabel' : 'epoch',\n",
        "        'ylabel' : 'value'\n",
        "    }\n",
        "  ACC.set(**acc_props)\n",
        "  ACC.plot(acc, label='acc', color='blue')\n",
        "  ACC.plot(val_acc, label='val_acc', color='orange')\n",
        "  ACC.legend(loc='best')\n",
        "\n",
        "  #2,1 loss.diff\n",
        "  loss_diff_props = {\n",
        "      'title' : 'Derivative values plot',\n",
        "      # 'xlabel' : 'epoch',\n",
        "      'ylabel' : 'value'\n",
        "  }\n",
        "  LOSSDIF.set(**loss_diff_props)\n",
        "  LOSSDIF.plot(loss.diff(), label='loss_diff', color='blue')\n",
        "  LOSSDIF.plot(val_loss.diff(), label='val_loss_diff', color='orange')\n",
        "  LOSSDIF.legend(loc='best')\n",
        "\n",
        "  # 2,2 learning outline\n",
        "  tmp = {\n",
        "      'title' : 'learning outline',\n",
        "      'xticks' : ([]),\n",
        "      'yticks' : ([]),\n",
        "  }\n",
        "\n",
        "  LEARNING_OUTLINE.set(**tmp)\n",
        "  LEARNING_OUTLINE.text(0.1, 0.5, modelOutline(elementsDict), size=10)\n",
        "\n",
        "  #save\n",
        "  path_image = os.path.join(desk, name)\n",
        "  fig.savefig(path_image, bbox_inches='tight')\n",
        "\n",
        "def modelOutline(elementsDict):\n",
        "  sentence = \"\"\n",
        "\n",
        "  for each in elementsDict.keys():\n",
        "    if isinstance(elementsDict[each], int):\n",
        "      sentence = sentence + each + \" : \" + str(elementsDict[each]) + \"\\n\"\n",
        "    else:\n",
        "      sentence = sentence + each + \" : \" + get_var_name(elementsDict[each]) + \"\\n\"\n",
        "\n",
        "  return sentence\n",
        "\n",
        "def get_var_name(var):\n",
        "    for k,v in globals().items():\n",
        "        if id(v) == id(var):\n",
        "            theName=k\n",
        "    return theName\n",
        "\n",
        "# plot(history, elementsDict)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OOmcZMqXnKn"
      },
      "source": [
        "%%time\n",
        "# 実行\n",
        "model = makeModel()\n",
        "history = model.fit(\n",
        "      train_videos, train_labels,\n",
        "      validation_data=(test_videos, test_labels),\n",
        "      batch_size=elementsDict[\"batch_size\"],\n",
        "      epochs=elementsDict[\"epochs\"],\n",
        "      verbose=0\n",
        "      )\n",
        "\n",
        "print(\"Complete.\")\n",
        "\n",
        "# プロット \n",
        "plot(history, elementsDict)\n",
        "plot_model(model, \n",
        "           show_shapes=True,\n",
        "           show_layer_names=False,\n",
        "           to_file='model.png')\n",
        "\n",
        "# 消去\n",
        "sleep(10)\n",
        "del model\n",
        "keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "beep()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}