{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMYCBjD4jLqPIJHq7Iu4+aG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1250103/Public_mori-lab/blob/preprcing-learning/experiments/preprcing-learning/learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pN9-YQe-Tke"
      },
      "source": [
        "# [スクラッチ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReeI66C5FVCn"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7aF5olQLzzr"
      },
      "source": [
        "# [環境構築]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gT21oClcYdI",
        "outputId": "183e3544-19d8-43bf-cd0a-a9faca2c18be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Hyperasやその他諸々の必要なライブラリをインポート\n",
        "!pip install hyperas\n",
        "!pip install hyperopt\n",
        "!pip install h5py\n",
        "\n",
        "from __future__ import print_function\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import itertools\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperas in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.4.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.0.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.11.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.5.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (4.3.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.2.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (4.7.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.11.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hyperas) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (20.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (20.8)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->hyperas) (2.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (51.0.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.11.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.19.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.19.4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-44652857b27b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT6HCp36Dh1R"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import layers, models, initializers, callbacks\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import gc\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VLZTe-_Fz-G",
        "outputId": "0d474d8d-aaf2-4563-d3a4-4c71347a2c2a"
      },
      "source": [
        "#@title gdrive マウント\n",
        "if not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print(\"Already confirm\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVHimjBTJ_7Y"
      },
      "source": [
        "#@title 一時的にファイルを置くディレクトリ'desk'を作成\n",
        "desk = '/content/desk'\n",
        "if not os.path.exists(desk):\n",
        "  os.mkdir(desk)\n",
        "os.chdir(desk)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYjxmEMpAZU1",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b97373a-0717-4176-b454-27e6bf3d99b5"
      },
      "source": [
        "#@title 必要なファイルを'desk'にコピー\n",
        "%%time\n",
        "wants_paths = [\n",
        "'/content/drive/MyDrive/colab/dence1223/key20201218.h5',\n",
        "'/content/drive/MyDrive/colab/dence1223/normalTrainLabels.npz',\n",
        "'/content/drive/MyDrive/colab/dence1223/normalTrainVideos.npz',\n",
        "'/content/drive/MyDrive/colab/dence1223/normalTestLabels.npz',\n",
        "'/content/drive/MyDrive/colab/dence1223/normalTestVideos.npz'\n",
        "]\n",
        "\n",
        "for want in wants_paths:\n",
        "  if not os.path.exists(os.path.join(desk, os.path.basename(want))):\n",
        "    shutil.copy2(want, desk)\n",
        "    print(\"get : \", want)\n",
        "            "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "get :  /content/drive/MyDrive/colab/dence1223/key20201218.h5\n",
            "get :  /content/drive/MyDrive/colab/dence1223/normalTrainLabels.npz\n",
            "get :  /content/drive/MyDrive/colab/dence1223/normalTrainVideos.npz\n",
            "get :  /content/drive/MyDrive/colab/dence1223/normalTestLabels.npz\n",
            "get :  /content/drive/MyDrive/colab/dence1223/normalTestVideos.npz\n",
            "CPU times: user 689 ms, sys: 1.94 s, total: 2.63 s\n",
            "Wall time: 53.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBIQL82BN3Ny"
      },
      "source": [
        "#@title データフォーマットを規定\n",
        "class video_format:\n",
        "  name = \"video_format\"\n",
        "  # サンプリングされたCMデータの仕様\n",
        "  playtime = \"15秒\"\n",
        "  displaysize = \"(any, any, RGB)\"\n",
        "  videoformat = \"any\"\n",
        "  # モデルが扱うCMデータ(上のようなデータは、下のように変換される)\n",
        "  HEIGHT = 45\n",
        "  WIDTH = 80\n",
        "  FRAME_SIZE = 30\n",
        "  COLOR = \"RGB\"\n",
        "  FPS = \"2 (FRAME_SIZE / playtime)\" # 定義ではなく上から導かれた値"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mYb1Eo8LzSZ"
      },
      "source": [
        "# [データ用意・学習準備]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z95hdLLJc-VD"
      },
      "source": [
        "format1 = video_format()\n",
        "colorSet = {'BW' : 1, 'RGB' : 3}\n",
        "\n",
        "def prepare_data():\n",
        "  # traindata\n",
        "  v = np.load('/content/desk/normalTrainVideos.npz')\n",
        "  l = np.load('/content/desk/normalTrainLabels.npz')\n",
        "\n",
        "  train_videos = [] \n",
        "  train_labels = []\n",
        "  for i in v.files:\n",
        "    train_videos.append(v[i])\n",
        "  for i in l.files:\n",
        "    train_labels.append(l[i])\n",
        "\n",
        "  train_videos = np.array(train_videos)\n",
        "  train_labels = np.array(train_labels)\n",
        "  train_labels = tf.keras.utils.to_categorical(train_labels, 4)\n",
        "\n",
        "  # testdata\n",
        "  v = np.load('/content/desk/normalTestVideos.npz')\n",
        "  l = np.load('/content/desk/normalTestLabels.npz')\n",
        "\n",
        "  test_videos = []\n",
        "  test_labels = []\n",
        "  for i in v.files:\n",
        "    test_videos.append(v[i])\n",
        "  for i in l.files:\n",
        "    test_labels.append(l[i])\n",
        "\n",
        "  test_videos = np.array(test_videos)\n",
        "  test_labels = np.array(test_labels)\n",
        "  test_labels = tf.keras.utils.to_categorical(test_labels, 4)\n",
        "\n",
        "  x_train = train_videos\n",
        "  y_train = train_labels\n",
        "  x_test = test_videos\n",
        "  y_test = test_labels\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weiihIiWesyF"
      },
      "source": [
        "x_train, y_train, x_test, y_test = prepare_data()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVNwqiU2HLBW"
      },
      "source": [
        "# [モデル作成]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtzpLCxfHGyt",
        "outputId": "8c54c92c-3a1c-416e-fcec-080af480bd8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "colorSet = {'BW' : 1, 'RGB' : 3}\n",
        "\n",
        "#入力層の設定\n",
        "input_frameWIDTH = format1.WIDTH\n",
        "input_frameHEIGHT = format1.HEIGHT\n",
        "input_frameSIZE = format1.FRAME_SIZE\n",
        "input_frameCOLOR = colorSet['RGB']\n",
        "input_allPattern = input_frameWIDTH * input_frameHEIGHT * input_frameSIZE * input_frameCOLOR\n",
        "\n",
        "print(\n",
        "    input_frameWIDTH,\n",
        "    input_frameHEIGHT,\n",
        "    input_frameSIZE,\n",
        "    input_frameCOLOR,\n",
        "    input_allPattern )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80 45 30 3 324000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW1o5O1cHSgm"
      },
      "source": [
        "seedKey = 20201218\n",
        "\n",
        "np.random.seed(seedKey)\n",
        "tf.random.set_seed(seedKey)\n",
        "\n",
        "model = models.Sequential([\n",
        "    # 入力層        \n",
        "    layers.Reshape(\n",
        "        (input_frameSIZE, input_frameHEIGHT, input_frameWIDTH,  input_frameCOLOR), \n",
        "        input_shape=(input_allPattern,),\n",
        "        name='ENTRANCE' ),\n",
        "    # 中間層\n",
        "    layers.Flatten(\n",
        "        name='RIVER' ),\n",
        "    layers.Dense(\n",
        "      1024, # 1024項\n",
        "      activation='relu',\n",
        "      name='DAM' ),\n",
        "    # 出力層\n",
        "    layers.Dense(4, activation='softmax', name='WATERSUPPLY')\n",
        "])\n",
        "\n",
        "name_model = 'key' + str(seedKey)\n",
        "name_model = name_model + '.h5'\n",
        "path_model = os.path.join('/content/desk/', name_model)\n",
        "model.save(path_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLRo4NSuIKew"
      },
      "source": [
        "def create_model(x_train, y_train, x_test, y_test):\n",
        "    model = Sequential()\n",
        "    # 入力層    \n",
        "    model.add(\n",
        "        layers.Reshape(\n",
        "        (input_frameSIZE, input_frameHEIGHT, input_frameWIDTH,  input_frameCOLOR), \n",
        "        input_shape=(input_allPattern,),\n",
        "        name='ENTRANCE' )\n",
        "    )\n",
        "  # 中間層\n",
        "    model.add(\n",
        "        layers.Flatten(\n",
        "        name='RIVER' ),\n",
        "    )\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "      {{choice([216, 512, 1024])}},\n",
        "      activation='relu',\n",
        "      name='DAM' ),\n",
        "    )\n",
        "    \n",
        "    # 出力層\n",
        "    model.add(\n",
        "        layers.Dense(4, activation='softmax', name='WATERSUPPLY')\n",
        "    )\n",
        "\n",
        "    # コンパイル\n",
        "    model.compile(\n",
        "    optimizer=keras.optimizers.SGD(lr=lr, momentum=0.0, decay=0.0, nesterov=False),\n",
        "    loss=loss,\n",
        "    metrics=['acc', cce])\n",
        "\n",
        "\n",
        "    return {'loss': -val_acc, 'status': STATUS_OK, 'model': model}\n",
        "\n",
        "\n",
        "create_model(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "yR2-LDpJRmuo",
        "outputId": "b8756ab0-d5bb-40fb-9549-a2bf3dcde3ed"
      },
      "source": [
        "def create_model(x_train, y_train, x_test, y_test):\n",
        "    model = Sequential()\n",
        "    # 入力層    \n",
        "    model.add(\n",
        "        layers.Reshape(\n",
        "        (input_frameSIZE, input_frameHEIGHT, input_frameWIDTH,  input_frameCOLOR), \n",
        "        input_shape=(input_allPattern,),\n",
        "        name='ENTRANCE' )\n",
        "    )\n",
        "  # 中間層\n",
        "    model.add(\n",
        "        layers.Flatten(\n",
        "        name='RIVER' ),\n",
        "    )\n",
        "    model.add(\n",
        "        layers.Dense(\n",
        "      {{choice([216, 512, 1024])}},\n",
        "      activation='relu',\n",
        "      name='DAM' ),\n",
        "    )\n",
        "    \n",
        "    # 出力層\n",
        "    model.add(\n",
        "        layers.Dense(4, activation='softmax', name='WATERSUPPLY')\n",
        "    )\n",
        "\n",
        "    # コンパイル\n",
        "    model.compile(\n",
        "    optimizer=keras.optimizers.SGD(lr=lr, momentum=0.0, decay=0.0, nesterov=False),\n",
        "    loss=loss,\n",
        "    metrics=['acc', cce])\n",
        "\n",
        "\n",
        "    return {'loss': -val_acc, 'status': STATUS_OK, 'model': model}\n",
        "\n",
        "\n",
        "create_model(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-06ae50d9b10f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-06ae50d9b10f>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m     15\u001b[0m     model.add(\n\u001b[1;32m     16\u001b[0m         layers.Dense(\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0;34m{\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m216\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       name='DAM' ),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/pyll_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(label, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m                              isinstance(label.obj, basestring))\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_real_string\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_literal_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'require string label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: require string label"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asNeM42iIf5W"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r9o9ibKKW3R"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb9UHlY_c7XV"
      },
      "source": [
        "プロット"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6JeXdD4PsaV"
      },
      "source": [
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def plot(history):\n",
        "  HEIGHT = 2\n",
        "  WIDTH = 2\n",
        "\n",
        "  # 下地の用意\n",
        "  fig = plt.figure()\n",
        "  LOSS = fig.add_subplot(HEIGHT, WIDTH, 1)\n",
        "  ACC = fig.add_subplot(HEIGHT, WIDTH, 2)\n",
        "  LOSSDIF = fig.add_subplot(HEIGHT, WIDTH, 3)\n",
        "  plt.subplots_adjust(left=None, bottom=None, right=1.5, top=1.5, wspace=None, hspace=None)\n",
        "\n",
        "  # 1,1 loss\n",
        "  loss = DataFrame(history.history['loss'])\n",
        "  val_loss = DataFrame(history.history['val_loss'])\n",
        "  loss_props = {\n",
        "        'title' : 'LOSS',\n",
        "        'xlabel' : 'epoch',\n",
        "        'ylabel' : 'value'\n",
        "    }\n",
        "  LOSS.set(**loss_props)\n",
        "  LOSS.plot(loss, label='loss', marker='o', color='blue')\n",
        "  LOSS.plot(val_loss, label='val_loss', marker='o', linestyle='--', color='orange')\n",
        "\n",
        "  # 1,2 acc\n",
        "  acc = DataFrame(history.history['acc'])\n",
        "  val_acc = DataFrame(history.history['val_acc'])\n",
        "  acc_props = {\n",
        "        'title' : 'ACCURACY',\n",
        "        'xlabel' : 'epoch',\n",
        "        'ylabel' : 'value'\n",
        "    }\n",
        "  ACC.set(**acc_props)\n",
        "  ACC.plot(acc, label='acc', marker='o', color='blue')\n",
        "  ACC.plot(val_acc, label='val_acc', marker='o', linestyle='--', color='orange')\n",
        "\n",
        "  #2,1 loss.diff\n",
        "  LOSSDIF.plot(loss.diff())\n",
        "  LOSSDIF.plot(val_loss.diff())\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  #save\n",
        "  name = 'tmp'\n",
        "  path_image = os.path.join(desk, name)\n",
        "  fig.savefig(path_image)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu5-RNhBFk6t"
      },
      "source": [
        "一覧"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-1ykomzuNT7"
      },
      "source": [
        "# loss一覧\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# optimizer一覧\n",
        "sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN9MMkqbuYv9"
      },
      "source": [
        "# [[学習実行]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsOKFK1vG5Nm"
      },
      "source": [
        "class mySGD:\n",
        "  l\n",
        "\n",
        "def learning(optimizer, loss):\n",
        "  pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  optimizer = \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYUPctH6fKa7"
      },
      "source": [
        "x_train, y_train, x_test, y_test = prepare_data()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QC5NCn1GAbM"
      },
      "source": [
        "#学習設定\n",
        "%%time\n",
        "loss=cce\n",
        "lr=0.00001\n",
        "\n",
        "\n",
        "# モデル準備\n",
        "model = models.load_model('/content/desk/key20201218.h5')\n",
        "\n",
        "# コンパイル\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(lr=lr, momentum=0.0, decay=0.0, nesterov=False),\n",
        "    loss=loss,\n",
        "    metrics=['acc', cce])\n",
        "\n",
        "# 実行\n",
        "history = model.fit(\n",
        "      x_train,\n",
        "      y_train, \n",
        "      validation_data=(x_test, y_test),\n",
        "      batch_size=16,\n",
        "      epochs=512,\n",
        "      # verbose=0\n",
        "      )\n",
        "print(\"Complete.\")\n",
        "\n",
        "# プロット\n",
        "plot(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xECtuTNphxI"
      },
      "source": [
        "#[ストレージへ保存]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss4IH3BWq1ed"
      },
      "source": [
        "shelf = '/content/drive/MyDrive/colab'\n",
        "book = 'dence1223'\n",
        "shelf_book = os.path.join(shelf, book)\n",
        "if not os.path.exists(shelf_book):\n",
        "  os.mkdir(shelf_book)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df4WB_241-X9"
      },
      "source": [
        "wants_paths = [\n",
        "'/content/desk/normalTestLabels.npz',\n",
        "'/content/desk/normalTestVideos.npz'\n",
        "]    \n",
        "\n",
        "for want in wants_paths:\n",
        "  shutil.copy2(\n",
        "      want,\n",
        "      shelf_book\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4fLap4v1xYb"
      },
      "source": [
        "#[掃き溜め]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbR5DmQysEJl"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip2 install --upgrade google-auth-oauthlib grpcio >/dev/null 2>&1\n",
        "import shutil\n",
        "from tensorflow.keras import layers, models, initializers, callbacks\n",
        "log_dir = '/tmp/log'\n",
        "shutil.rmtree(log_dir, ignore_errors=True)\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir,\n",
        "                                             histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_jDvyYmDkYG"
      },
      "source": [
        "losses = {\n",
        "    'CCE' : 'categorical_crossentropy',\n",
        "    'SCE' : 'sparse_categorical_crossentropy',\n",
        "\n",
        "    'MSE' : 'mean_squared_error',\n",
        "    'MSLE' : 'mean_squared_logarithmic_error',\n",
        "    'MAE' : 'mean_absolute_error',\n",
        "}\n",
        "def inverse_dict(d):\n",
        "    return {v:k for k,v in d.items()}\n",
        "\n",
        "inv_losses = inverse_dict(losses)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_l9fiK4yfVu"
      },
      "source": [
        "#@title 学習\n",
        "%%time\n",
        "history = model.fit(\n",
        "      train_videos, train_labels, \n",
        "      validation_data=(test_videos, test_labels),\n",
        "      batch_size=16, epochs= 30,\n",
        "      # callbacks=[tensorboard_callback]\n",
        "      )\n",
        "print(\"Complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCneOHGy6VXw"
      },
      "source": [
        "!curl -OL https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3oGrHRwWz58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77002d56-abf7-48b7-8160-f5523bd62275"
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(log_dir)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://6b5d01d27e35.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}